{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/zip\"\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['hashtags']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Split hashtags by comma\n",
    "                    tags = row.split(',')\n",
    "                    \n",
    "                    # Iterate over each hashtag\n",
    "                    for tag in tags:\n",
    "                        # Remove leading and trailing whitespaces\n",
    "                        tag = tag.strip()\n",
    "                        \n",
    "                        # Increment the count for the hashtag in the dictionary\n",
    "                        if tag in hashtags:\n",
    "                            hashtags[tag] += 1\n",
    "                        else:\n",
    "                            hashtags[tag] = 1\n",
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "top_100_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "for tag, count in top_100_hashtags:\n",
    "    print(tag, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ed.zip\"\n",
    "\n",
    "# Create an empty dictionary to store users and their counts\n",
    "users = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for user in df['userid']:\n",
    "            # Check if the user is not empty\n",
    "            if pd.notnull(user):\n",
    "                # Increment the count for the user in the dictionary\n",
    "                if user in users:\n",
    "                    users[user] += 1\n",
    "                else:\n",
    "                    users[user] = 1\n",
    "\n",
    "# Sort the users dictionary by count in descending order and get the top 100\n",
    "top_100_users = sorted(users.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the users and their counts into separate lists\n",
    "users_list = [user[0] for user in top_100_users]\n",
    "counts_list = [user[1] for user in top_100_users]\n",
    "\n",
    "# Plot the top 100 users on a horizontal bar graph\n",
    "plt.barh(range(len(users_list)), counts_list, tick_label=users_list)\n",
    "plt.xlabel('Tweet Counts')\n",
    "plt.ylabel('Users')\n",
    "plt.title('Top 100 Users by Tweet Counts')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/cd.zip\"\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['hashtags']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split hashtags by comma\n",
    "                tags = row[1:-1].split(',')\n",
    "                tags = [t.strip() for t in tags if t.strip() != \"\"]\n",
    "                # Iterate over each hashtag\n",
    "                for tag in tags:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tag = tag.strip()\n",
    "                    # Increment the count for the hashtag in the dictionary\n",
    "                    if tag in hashtags:\n",
    "                        hashtags[tag] += 1\n",
    "                    else:\n",
    "                        hashtags[tag] = 1\n",
    "\n",
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "top_100_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "for tag, count in top_100_hashtags:\n",
    "    print(tag, count)\n",
    "\n",
    "# Plot the top 100 hashtags\n",
    "plt.figure(figsize=(22, 6))\n",
    "plt.bar(hashtags_list, counts_list)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Hashtags')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 100 Most Frequent Hashtags')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/cd.zip\"\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['hashtags']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split hashtags by comma\n",
    "                tags = row.split(',')\n",
    "                # Iterate over each hashtag\n",
    "                for tag in tags:\n",
    "                    tag = tag.strip()  # Remove leading and trailing whitespaces\n",
    "                    if tag and tag != \"[]\" and \"[\" not in tag and \"]\" not in tag:\n",
    "                        # Increment the count for the hashtag in the dictionary\n",
    "                        if tag in hashtags:\n",
    "                            hashtags[tag] += 1\n",
    "                        else:\n",
    "                            hashtags[tag] = 1\n",
    "\n",
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "top_100_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "for tag, count in top_100_hashtags:\n",
    "    print(tag, count)\n",
    "\n",
    "# Plot the top 100 hashtags\n",
    "plt.figure(figsize=(22, 6))\n",
    "plt.bar(hashtags_list, counts_list)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Hashtags')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 100 Most Frequent Hashtags')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ip\"\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['hashtags']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split hashtags by comma\n",
    "                tags = row.split(',')\n",
    "                # Iterate over each hashtag\n",
    "                for tag in tags:\n",
    "                    tag = tag.strip()  # Remove leading and trailing whitespaces\n",
    "                    if tag and tag != \"[]\" and \"[\" not in tag and \"]\" not in tag:\n",
    "                        # Increment the count for the hashtag in the dictionary\n",
    "                        if tag in hashtags:\n",
    "                            hashtags[tag] += 1\n",
    "                        else:\n",
    "                            hashtags[tag] = 1\n",
    "\n",
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "top_100_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "for tag, count in top_100_hashtags:\n",
    "    print(tag, count)\n",
    "\n",
    "# Divide the plot into three maps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(40, 10), sharey=True)\n",
    "plt.subplots_adjust(wspace=0.05)  # Adjust the space between subplots\n",
    "\n",
    "#Define color\n",
    "colors = ['gold']\n",
    "\n",
    "# Plot the bar graphs with logarithmic scale\n",
    "for i, ax in enumerate(axes):\n",
    "    start_idx = i * 33\n",
    "    end_idx = (i + 1) * 33\n",
    "    sub_hashtags = tags[start_idx:end_idx]\n",
    "    sub_counts = count[start_idx:end_idx]\n",
    "    \n",
    "    # Reverse the order of hashtags and counts\n",
    "    sub_hashtags = sub_hashtags[::-1]\n",
    "    sub_counts = sub_counts[::-1]\n",
    "    \n",
    "    bars = ax.barh(sub_hashtags, sub_counts, height=0.8,color=colors)  # Adjust the height parameter to make bars thicker\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel('Counts')  # Swap x-axis and y-axis labels\n",
    "    ax.set_ylabel('Hashtags')  # Swap x-axis and y-axis labels\n",
    "    ax.set_title(f'Top 100 Hashtags (Part {i+1})')\n",
    "    ax.set_xscale('log')  # Set x-axis scale to logarithmic\n",
    "    \n",
    "    # Add labels to the bars\n",
    "    for bar, count, hashtag in zip(bars, sub_counts, sub_hashtags):\n",
    "        ax.text(count, bar.get_y() + bar.get_height() / 2, str(count), va='center')\n",
    "        ax.text(count, bar.get_y() + bar.get_height() / 2, hashtag, va='center', ha='right', color='black', weight='bold')\n",
    "\n",
    "\n",
    "    # Remove y-axis labels\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YENi KOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ct.zip\"\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['hashtags']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split hashtags by comma\n",
    "                tags = row[1:-1].split(',')\n",
    "                tags = [t.strip() for t in tags if t.strip() != \"\"]\n",
    "                # Iterate over each hashtag\n",
    "                for tag in tags:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tag = tag.strip().lower()[1:-1]\n",
    "                    # Increment the count for the hashtag in the dictionary\n",
    "                    if tag in hashtags:\n",
    "                        hashtags[tag] += 1\n",
    "                    else:\n",
    "                        hashtags[tag] = 1\n",
    "\n",
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "top_100_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "for tag, count in top_100_hashtags:\n",
    "    print(tag, count)\n",
    "\n",
    "# Plot the top 100 hashtags\n",
    "plt.figure(figsize=(22, 6))\n",
    "plt.bar(hashtags_list, counts_list)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Hashtags')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 100 Most Frequent Hashtags')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "# Divide the plot into three maps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(40, 10), sharey=False)\n",
    "plt.subplots_adjust(wspace=0.05)  # Adjust the space between subplots\n",
    "\n",
    "# Define color\n",
    "colors = ['gold']\n",
    "\n",
    "# Plot the bar graphs with logarithmic scale\n",
    "for i, ax in enumerate(axes):\n",
    "    start_idx = i * 33\n",
    "    end_idx = (i + 1) * 33\n",
    "    sub_hashtags = hashtags_list[start_idx:end_idx]\n",
    "    sub_counts = counts_list[start_idx:end_idx]\n",
    "    \n",
    "    # Reverse the order of hashtags and counts\n",
    "    sub_hashtags = sub_hashtags[::-1]\n",
    "    sub_counts = sub_counts[::-1]\n",
    "    \n",
    "    bars = ax.barh(sub_hashtags, sub_counts, height=0.8, color=colors)  # Adjust the height parameter to make bars thicker\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel('Counts')  # Swap x-axis and y-axis labels\n",
    "    ax.set_ylabel('Hashtags')  # Swap x-axis and y-axis labels\n",
    "    ax.set_title(f'Top 100 Hashtags (Part {i+1})')\n",
    "    # ax.set_xscale('log')  # Set x-axis scale to logarithmic\n",
    "    \n",
    "    # Add labels to the bars\n",
    "    for bar, count, hashtag in zip(bars, sub_counts, sub_hashtags):\n",
    "        # ax.text(count, bar.get_y() + bar.get_height() / 2  , str(count), va='center')\n",
    "        ax.text(bar.get_x() + 5, bar.get_y() + bar.get_height() / 2, f\"{hashtag},{str(count)}\", va='center', ha='left', color='black', weight='bold')\n",
    "\n",
    "    # Remove y-axis labels\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xlim(0, max(counts_list))\n",
    "plt.savefig(\"graph.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top 100 hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/d.zip\"\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['hashtags']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split hashtags by comma\n",
    "                tags = row[1:-1].split(',')\n",
    "                tags = [t.strip() for t in tags if t.strip() != \"\"]\n",
    "                # Iterate over each hashtag\n",
    "                for tag in tags:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tag = tag.strip().lower()[1:-1]\n",
    "                    # Increment the count for the hashtag in the dictionary\n",
    "                    if tag in hashtags:\n",
    "                        hashtags[tag] += 1\n",
    "                    else:\n",
    "                        hashtags[tag] = 1\n",
    "\n",
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "top_100_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=False)[:100]\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "# Plot the horizontal bar graph on a logarithmic scale\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.barh(hashtags_list, counts_list)\n",
    "plt.xscale('log')  # Set logarithmic scale on the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Hashtags')\n",
    "plt.title('Top 100 Hashtags on a Logarithmic Scale')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to display in descending order\n",
    "plt.tight_layout()  # Ensure labels are not cut off\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top100 Client Name Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['tweet_client_name']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    client_name = row.strip()\n",
    "                        \n",
    "                    # Increment the count for the tweet client in the dictionary\n",
    "                    if client_name in tweet_clients:\n",
    "                        tweet_clients[client_name] += 1\n",
    "                    else:\n",
    "                        tweet_clients[client_name] = 1\n",
    "\n",
    "# Sort the tweet clients dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_clients = sorted(tweet_clients.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet clients and their counts into separate lists\n",
    "tweet_clients_list = [client[0] for client in top_100_tweet_clients]\n",
    "counts_list = [client[1] for client in top_100_tweet_clients]\n",
    "\n",
    "for client, count in top_100_tweet_clients:\n",
    "    print(client, count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 Clients Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/c.zip\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['tweet_client_name']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    client_name = row.strip()\n",
    "\n",
    "                    # Increment the count for the tweet client in the dictionary\n",
    "                    if client_name in tweet_clients:\n",
    "                        tweet_clients[client_name] += 1\n",
    "                    else:\n",
    "                        tweet_clients[client_name] = 1\n",
    "\n",
    "# Sort the tweet clients dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_clients = sorted(tweet_clients.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet clients and their counts into separate lists\n",
    "tweet_clients_list = [client[0] for client in top_100_tweet_clients][::-1]  # Reverse the list\n",
    "counts_list = [client[1] for client in top_100_tweet_clients][::-1]  # Reverse the list\n",
    "\n",
    "# Create a bar graph for the top 100 tweet clients and their counts\n",
    "plt.figure(figsize=(15, 15))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(tweet_clients_list, counts_list, height=0.5, color='blue')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Tweet Client')\n",
    "plt.title('Top 100 Tweet Clients and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='left', va='center')\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(tweet_clients_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Tweet Client')\n",
    "plt.title('Top 100 Tweet Clients and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# plt.savefig(\"top100clients.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ctc/Dip\"\n",
    "\n",
    "# Create an empty dictionary to store usernames and their counts\n",
    "usernames = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['user_display_name']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    username = row.strip()\n",
    "\n",
    "                    # Increment the count for the username in the dictionary\n",
    "                    if username in usernames:\n",
    "                        usernames[username] += 1\n",
    "                    else:\n",
    "                        usernames[username] = 1\n",
    "\n",
    "# Sort the usernames dictionary by count in descending order and get the top 100\n",
    "top_100_usernames = sorted(usernames.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the usernames and their counts into separate lists\n",
    "username_list = [user[0] for user in top_100_usernames][::-1]  # Reverse the list\n",
    "counts_list = [user[1] for user in top_100_usernames][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(username_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Username')\n",
    "plt.title('Top 100 Usernames and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Uncomment the following line to save the plot as a PDF file\n",
    "# plt.savefig(\"top100usernames.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the usernames dictionary by count in descending order and get the top 100\n",
    "top_100_usernames = sorted(usernames.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the usernames and their counts into separate lists\n",
    "username_list = [user[0] for user in top_100_usernames][::-1]  # Reverse the list\n",
    "counts_list = [user[1] for user in top_100_usernames][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(username_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Username')\n",
    "plt.title('Top 100 Usernames and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Uncomment the following line to save the plot as a PDF file\n",
    "plt.savefig(\"top100usernames.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 User IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ctc/zip\"\n",
    "\n",
    "# Create an empty dictionary to store user IDs and their counts\n",
    "user_ids = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['userid']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Increment the count for the user ID in the dictionary\n",
    "                    if row in user_ids:\n",
    "                        user_ids[row] += 1\n",
    "                    else:\n",
    "                        user_ids[row] = 1\n",
    "\n",
    "# Sort the user IDs dictionary by count in descending order and get the top 100\n",
    "top_100_user_ids = sorted(user_ids.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user IDs and their counts into separate lists\n",
    "user_ids_list = [user[0] for user in top_100_user_ids][::-1]  # Reverse the list\n",
    "counts_list = [user[1] for user in top_100_user_ids][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_ids_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User ID')\n",
    "plt.title('Top 100 User IDs and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Uncomment the following line to save the plot as a PDF file\n",
    "# plt.savefig(\"top100userids.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 Tweet Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ctp\"\n",
    "\n",
    "# Create an empty dictionary to store tweet times and their counts\n",
    "tweet_times = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for time in df['tweet_time']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(time):\n",
    "                    # Increment the count for the tweet time in the dictionary\n",
    "                    if time in tweet_times:\n",
    "                        tweet_times[time] += 1\n",
    "                    else:\n",
    "                        tweet_times[time] = 1\n",
    "\n",
    "# Sort the tweet times dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_times = sorted(tweet_times.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet times and their counts into separate lists\n",
    "tweet_times_list = [time[0] for time in top_100_tweet_times][::-1]  # Reverse the list\n",
    "counts_list = [time[1] for time in top_100_tweet_times][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "bars = plt.barh(tweet_times_list, counts_list, height=0.7, color='blue')  # Set the bar height and color\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Tweet Time')\n",
    "plt.title('Top 100 Tweet Times and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='left', va='center', color='black', fontsize=10)\n",
    "\n",
    "autolabel(bars)\n",
    "#plt.savefig(\"top100tweettimes.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (tweet_times_list, count) in enumerate(zip(tweet_times_list, counts_list)):\n",
    "    print(f\"{i+1}. Tweet: {tweet_times}\")\n",
    "    print(f\"   Count: {count}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top100 Account Creation Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ip\"\n",
    "\n",
    "# Create an empty dictionary to store account creation dates and their counts\n",
    "account_creation_dates = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for date in df['account_creation_date']:\n",
    "                # Check if the date is not empty\n",
    "                if pd.notnull(date):\n",
    "                    # Increment the count for the date in the dictionary\n",
    "                    if date in account_creation_dates:\n",
    "                        account_creation_dates[date] += 1\n",
    "                    else:\n",
    "                        account_creation_dates[date] = 1\n",
    "\n",
    "# Sort the account creation dates dictionary by count in descending order and get the top 100\n",
    "top_100_dates = sorted(account_creation_dates.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the dates and their counts into separate lists\n",
    "dates_list = [date[0] for date in top_100_dates][::-1]  # Reverse the list\n",
    "counts_list = [date[1] for date in top_100_dates][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(dates_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Account Creation Date')\n",
    "plt.title('Top 100 Account Creation Dates and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "#plt.savefig(\"top100taccountcreation.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top100 Tweet Texts for most RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/c\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_texts = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "\n",
    "                    # Increment the count for the tweet text in the dictionary\n",
    "                    if tweet_text in tweet_texts:\n",
    "                        tweet_texts[tweet_text] += 1\n",
    "                    else:\n",
    "                        tweet_texts[tweet_text] = 1\n",
    "\n",
    "# Sort the tweet texts dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_texts = sorted(tweet_texts.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet texts and their counts into separate lists\n",
    "tweet_texts_list = [tweet[0] for tweet in top_100_tweet_texts][::-1]  # Reverse the list\n",
    "counts_list = [tweet[1] for tweet in top_100_tweet_texts][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(tweet_texts_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Tweet Text')\n",
    "plt.title('Top 100 Tweet Texts and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot as a PDF file (optional)\n",
    "# plt.savefig(\"top100tweettexts.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (tweet_text, count) in enumerate(zip(tweet_texts_list, counts_list)):\n",
    "    print(f\"{i+1}. Tweet: {tweet_text}\")\n",
    "    print(f\"   Count: {count}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top100 Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/c\"\n",
    "\n",
    "# Create an empty dictionary to store tweet languages and their counts\n",
    "tweet_languages = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['tweet_language']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    language = row.strip()\n",
    "\n",
    "                    # Increment the count for the tweet language in the dictionary\n",
    "                    if language in tweet_languages:\n",
    "                        tweet_languages[language] += 1\n",
    "                    else:\n",
    "                        tweet_languages[language] = 1\n",
    "\n",
    "# Sort the tweet languages dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_languages = sorted(tweet_languages.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet languages and their counts into separate lists\n",
    "tweet_languages_list = [language[0] for language in top_100_tweet_languages][::-1]  # Reverse the list\n",
    "counts_list = [language[1] for language in top_100_tweet_languages][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(tweet_languages_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Tweet Language')\n",
    "plt.title('Top 100 Tweet Languages and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "# plt.savefig(\"top100languages.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 Hashtag Count (single graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the hashtags dictionary by count in descending order and get the top 100\n",
    "top_100_hashtags = sorted(hashtags.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the hashtags and their counts into separate lists\n",
    "hashtags_list = [tag[0] for tag in top_100_hashtags]\n",
    "counts_list = [tag[1] for tag in top_100_hashtags]\n",
    "\n",
    "# Reverse the order of hashtags_list and counts_list to have the highest count on top\n",
    "hashtags_list = hashtags_list[::-1]\n",
    "counts_list = counts_list[::-1]\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(hashtags_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Hashtag')\n",
    "plt.title('Top 100 Hashtags and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "plt.savefig(\"top100hashtags.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top100 urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/zip\"\n",
    "\n",
    "# Create an empty dictionary to store URLs and their counts\n",
    "urls_dict = {}\n",
    "\n",
    "# Function to extract URLs from tweet text using regex\n",
    "def extract_urls(tweet_text):\n",
    "    return re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\\\\\(\\\\\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', tweet_text)\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for tweet_text in df['tweet_text']:\n",
    "                # Check if the tweet text is not empty\n",
    "                if pd.notnull(tweet_text):\n",
    "                    # Extract URLs from tweet text\n",
    "                    urls = extract_urls(tweet_text)\n",
    "                    for url in urls:\n",
    "                        # Increment the count for the URL in the dictionary\n",
    "                        if url in urls_dict:\n",
    "                            urls_dict[url] += 1\n",
    "                        else:\n",
    "                            urls_dict[url] = 1\n",
    "\n",
    "# Sort the URLs dictionary by count in descending order and get the top 100\n",
    "top_100_urls = sorted(urls_dict.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the URLs and their counts into separate lists\n",
    "urls_list = [url[0] for url in top_100_urls][::-1]  # Reverse the list\n",
    "counts_list = [url[1] for url in top_100_urls][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(urls_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('URL')\n",
    "plt.title('Top 100 URLs and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\"# plt.savefig(\\\"top100urls.pdf\\\", bbox_inches=\\\"tight\\\", dpi=300, format=\\\"pdf\\\")\",\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top100 User Replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/zip\"\n",
    "\n",
    "# Create a list to store user replies\n",
    "user_replies = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            # Filter tweets that are replies and have a valid 'in_reply_to_userid'\n",
    "            replies = df[df['in_reply_to_userid'].notnull()]['in_reply_to_userid'].tolist()\n",
    "            # Extend the user_replies list with the extracted replies\n",
    "            user_replies.extend(replies)\n",
    "\n",
    "# Count the occurrences of each user ID in the user_replies list\n",
    "user_reply_counts = {}\n",
    "for user_id in user_replies:\n",
    "    if user_id in user_reply_counts:\n",
    "        user_reply_counts[user_id] += 1\n",
    "    else:\n",
    "        user_reply_counts[user_id] = 1\n",
    "\n",
    "# Sort the user_reply_counts dictionary by count in descending order and get the top 100\n",
    "top_100_user_replies = sorted(user_reply_counts.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user IDs and their counts into separate lists\n",
    "user_id_list = [user_id[0] for user_id in top_100_user_replies][::-1]  # Reverse the list\n",
    "counts_list = [user_id[1] for user_id in top_100_user_replies][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_id_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User ID')\n",
    "plt.title('Top 100 User Replies and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "#plt.savefig(\"top100userreplies.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "id_to_handle = {\n",
    "    68034431: \"@RTErdogan\",\n",
    "    1628824092: \"@Akparti\",\n",
    "    155534196: \"@abdulhamitgul\",\n",
    "    272613386: \"@tcbestepe\",\n",
    "    236131165: \"@06melihgokcek\",\n",
    "    214017108: \"@dbdevletbahceli\",\n",
    "    1589135268: \"@Lokman_Erturk\",\n",
    "    737302248338952193: \"@BY\",\n",
    "    233614834: \"@bekirpakdemirli\",\n",
    "    161355169: \"@MHP_Bilgi\",\n",
    "    769869708359237632: \"@tcsavunma\",\n",
    "    18971997: \"@suleymansoylu\",\n",
    "    237451465: \"@kbbmustafaak\",\n",
    "    154140901: \"@kilicdarogluk\",\n",
    "    967087600426209281: \"@fahrettinaltun\",\n",
    "    255515879: \"@herkesicinCHP\",\n",
    "    254777933: \"@hasandogan\",\n",
    "    979992619362209792: \"@YildizFeti\",\n",
    "    194792183: \"@iletisim\",\n",
    "    1509778892: \"@gonulborann\",\n",
    "    1385680262: \"1385680262\",\n",
    "    810886674: \"@naci_agbal\",\n",
    "    895250727039369217: \"@fuatoktay\",\n",
    "    885222182: \"@BA_Yildirim\",\n",
    "    526832991: \"@muratcan373\",\n",
    "    902503200728731649: \"@iyiparti\",\n",
    "    369515882: \"@omerrcelik\",\n",
    "    1321952677: \"@mkulunk\",\n",
    "    550409055: \"@akbasmarkt\",\n",
    "    226219067: \"@MustafaSentop\",\n",
    "    34350322: \"@NumanKurtulmus\",\n",
    "    181567076: \"@Ahmet_Davutoglu\",\n",
    "    564749194: \"@avabdullahguler\",\n",
    "    4077072555: \"@_Tevazu_\",\n",
    "    204277565: \"@ziyaselcuk\",\n",
    "    153772652: \"@ikalin1\",\n",
    "    772694821840519168: \"@TSKGnkur\",\n",
    "    915867855090012160: \"@EmineErdogan\",\n",
    "    501024041: \"@receparac06\",\n",
    "    2309922296: \"2309922296\",\n",
    "    466757008: \"@ayseucar5\",\n",
    "    2693953496: \"@SemaAlfat\",\n",
    "    201339405: \"@turanbulent\",\n",
    "    1579982719: \"@AbiSayn\",\n",
    "    1482806160: \"@Yettingari_la\",\n",
    "    115216315: \"@yilmaztunc\",\n",
    "    397106208: \"@TheCimbomFacts\",\n",
    "    378802752: \"378802752\",\n",
    "    289435070: \"@ikiagustos\",\n",
    "    207085169: \"@mehmedmus\",\n",
    "    1495932654: \"@Djlaz1969Fevzi\",\n",
    "    609063409: \"@filiz175\",\n",
    "    2347061250: \"@delideli_0618_\",\n",
    "    182317200: \"@vekilince\",\n",
    "    765897180553043968: \"@erayyyNihal\",\n",
    "    2386809223: \"@tasdemir_cemile\",\n",
    "    229515050: \"@eczozgurozel\",\n",
    "    1690041488: \"@benstandart\",\n",
    "    2638260543: \"@SirMuratPL\",\n",
    "    3555190636: \"@EvitanNeslihan\",\n",
    "    1847174592: \"@Fatoss_ata\",\n",
    "    1899851310: \"@r__lcayirmeral\",\n",
    "    590346965: \"@meral_aksener\",\n",
    "    90854551: \"@nacibostanci\",\n",
    "    461305047: \"@TBMMGenelKurulu\",\n",
    "    293395910: \"@bekiservet\",\n",
    "    1421299758: \"@mehmetucum\",\n",
    "    744924164: \"@AvOzlemZengin\",\n",
    "    1128697424: \"@bir_nefer19\",\n",
    "    2363435375: \"@S_Luleci\",\n",
    "    1559824820: \"@7171eliflal\",\n",
    "    1132163245: \"@hzlandrc\",\n",
    "    422861505: \"@ekrem_imamoglu\",\n",
    "    945355840084742144: \"@mustafaaksutr\",\n",
    "    3297484329: \"@TC_Seri\",\n",
    "    2419895447: \"@bayramaygun2\",\n",
    "    2973073341: \"@cevreormanorgtr\",\n",
    "    2419895447: \"@bayramaygun2\",\n",
    "    85279775: \"@GittiGidiyor\",\n",
    "    2372060418: \"@TCYargitay\",\n",
    "    73740255: \"@zekikayahan\",\n",
    "    524102272: \"@AyhanBarut01\",\n",
    "    990621226002518023: \"@cenginyurt52\",\n",
    "    180604914: \"@SSSBBL777\",\n",
    "    381416280: \"@MTanal\",\n",
    "    1533148142: \"@yunuskilic36\",\n",
    "    92487173: \"@fatihportakal\",\n",
    "    1016972284035305472: \"@pekcan\",\n",
    "    471286854: \"@KucukkayaIsmail\",\n",
    "    3071570176: \"@arzuerdemDB\",\n",
    "    1499266621: \"@demarkesports\",\n",
    "    225774686: \"@nureda_k\",\n",
    "    368595348: \"@B_Palandoken\",\n",
    "    302777122: \"@ismailedebali\",\n",
    "    23186079: \"@GalatasaraySK\",\n",
    "    876745005561466880: \"@1881_KuvvaciMKA\",\n",
    "    81683900: \"@fatihtezcan\",\n",
    "    2979105539: \"@orhansaribalchp\",\n",
    "    2241899203: \"@softmasaj\",\n",
    "    2380241859: \"@ozgeesekerr81\",\n",
    "    924853066435846144: \"@TMetinsafak\"\n",
    "\n",
    "}\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/ctc/D\"\n",
    "\n",
    "# Create an empty dictionary to store user mentions and their counts\n",
    "user_mentions = {}\n",
    "\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['in_reply_to_userid']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                mention = str(row)\n",
    "\n",
    "                # Replace the mention with the corresponding handle if available\n",
    "                if mention.isdigit():  # Check if the mention is a numeric ID\n",
    "                    mention_id = int(mention)\n",
    "                    if mention_id in id_to_handle:\n",
    "                        mention = id_to_handle[mention_id]\n",
    "\n",
    "                # Increment the count for the user mention in the dictionary\n",
    "                if mention in user_mentions:\n",
    "                    user_mentions[mention] += 1\n",
    "                else:\n",
    "                    user_mentions[mention] = 1\n",
    "\n",
    "# Sort the user mentions dictionary by count in descending order and get the top 100\n",
    "top_100_user_mentions = sorted(user_mentions.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user mentions and their counts into separate lists\n",
    "user_mentions_list = [mention[0] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "counts_list = [mention[1] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_mentions_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 100 User Replies and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "# plt.savefig(\"top100userreplies.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_mentions_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 100 User Replies and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "plt.savefig(\"top100userreplies.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 User Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/cip\"\n",
    "\n",
    "# Create an empty dictionary to store user mentions and their counts\n",
    "user_mentions = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['user_mentions']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split user mentions by comma\n",
    "                mentions = row[1:-1].split(',')\n",
    "                mentions = [mention.strip() for mention in mentions if mention.strip() != \"\"]\n",
    "                # Iterate over each user mention\n",
    "                for mention in mentions:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    mention = mention.strip().lower()[1:-1]\n",
    "                    # Increment the count for the user mention in the dictionary\n",
    "                    if mention in user_mentions:\n",
    "                        user_mentions[mention] += 1\n",
    "                    else:\n",
    "                        user_mentions[mention] = 1\n",
    "\n",
    "# Sort the user mentions dictionary by count in descending order and get the top 100\n",
    "top_100_mentions = sorted(user_mentions.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user mentions and their counts into separate lists\n",
    "mentions_list = [mention[0] for mention in top_100_mentions]\n",
    "counts_list = [mention[1] for mention in top_100_mentions]\n",
    "\n",
    "\n",
    "# Sort the user_mentions dictionary by count in descending order and get the top 100\n",
    "top_100_user_mentions = sorted(user_mentions.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user mentions and their counts into separate lists\n",
    "user_mentions_list = [mention[0] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "counts_list = [mention[1] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_mentions_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 100 User Mentions and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "plt.savefig(\"top100usermentions.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "id_to_handle = {\n",
    "    68034431: \"@RTErdogan\",\n",
    "    1628824092: \"@Akparti\",\n",
    "    155534196: \"@abdulhamitgul\",\n",
    "    3160777371: \"3160777371\",\n",
    "    272613386: \"@tcbestepe\",\n",
    "    236131165: \"@06melihgokcek\",\n",
    "    214017108: \"@dbdevletbahceli\",\n",
    "    244659700: \"244659700\",\n",
    "    1589135268: \"@Lokman_Erturk\",\n",
    "    737302248338952193: \"@BY\",\n",
    "    233614834: \"@bekirpakdemirli\",\n",
    "    161355169: \"@MHP_Bilgi\",\n",
    "    769869708359237632: \"@tcsavunma\",\n",
    "    18971997: \"@suleymansoylu\",\n",
    "    237451465: \"@kbbmustafaak\",\n",
    "    154140901: \"@kilicdarogluk\",\n",
    "    967087600426209281: \"@fahrettinaltun\",\n",
    "    255515879: \"@herkesicinCHP\",\n",
    "    254777933: \"@hasandogan\",\n",
    "    979992619362209792: \"@YildizFeti\",\n",
    "    194792183: \"@iletisim\",\n",
    "    1509778892: \"@gonulborann\",\n",
    "    762053863369302016: \"762053863369302016\",\n",
    "    1385680262: \"1385680262\",\n",
    "    810886674: \"@naci_agbal\",\n",
    "    895250727039369217: \"@fuatoktay\",\n",
    "    885222182: \"@BA_Yildirim\",\n",
    "    2261268656: \"2261268656\",\n",
    "    704390419451387904: \"704390419451387904\",\n",
    "    526832991: \"@muratcan373\",\n",
    "    751570558454751232: \"751570558454751232\",\n",
    "    902503200728731649: \"@iyiparti\",\n",
    "    937058248133431296: \"937058248133431296\",\n",
    "    369515882: \"@omerrcelik\",\n",
    "    1321952677: \"@mkulunk\",\n",
    "    550409055: \"@akbasmarkt\",\n",
    "    226219067: \"@MustafaSentop\",\n",
    "    34350322: \"@NumanKurtulmus\",\n",
    "    181567076: \"@Ahmet_Davutoglu\",\n",
    "    564749194: \"@avabdullahguler\",\n",
    "    4077072555: \"@_Tevazu_\",\n",
    "    204277565: \"@ziyaselcuk\",\n",
    "    153772652: \"@ikalin1\",\n",
    "    772694821840519168: \"@TSKGnkur\",\n",
    "    915867855090012160: \"@EmineErdogan\",\n",
    "    2827024772: \"2827024772\",\n",
    "    501024041: \"@receparac06\",\n",
    "    2871475105: \"2871475105\",\n",
    "    2309922296: \"2309922296\",\n",
    "    466757008: \"@ayseucar5\",\n",
    "    2693953496: \"@SemaAlfat\",\n",
    "    201339405: \"@turanbulent\",\n",
    "    1579982719: \"@AbiSayn\",\n",
    "    118447677: \"118447677\",\n",
    "    1482806160: \"@Yettingari_la\",\n",
    "    115216315: \"@yilmaztunc\",\n",
    "    397106208: \"@TheCimbomFacts\",\n",
    "    378802752: \"378802752\",\n",
    "    289435070: \"@ikiagustos\",\n",
    "    207085169: \"@mehmedmus\",\n",
    "    1495932654: \"@Djlaz1969Fevzi\",\n",
    "    609063409: \"@filiz175\",\n",
    "    2347061250: \"@delideli_0618_\",\n",
    "    182317200: \"@vekilince\",\n",
    "    765897180553043968: \"@erayyyNihal\",\n",
    "    2386809223: \"@tasdemir_cemile\",\n",
    "    229515050: \"@eczozgurozel\",\n",
    "    1690041488: \"@benstandart\",\n",
    "    2638260543: \"@SirMuratPL\",\n",
    "    3555190636: \"@EvitanNeslihan\",\n",
    "    1847174592: \"@Fatoss_ata\",\n",
    "    876521220791029760: \"876521220791029760\",\n",
    "    1056879184365142016: \"1056879184365142016\",\n",
    "    1899851310: \"@r__lcayirmeral\",\n",
    "    590346965: \"@meral_aksener\",\n",
    "    90854551: \"@nacibostanci\",\n",
    "    461305047: \"@TBMMGenelKurulu\",\n",
    "    293395910: \"@bekiservet\",\n",
    "    1421299758: \"@mehmetucum\",\n",
    "    744924164: \"@AvOzlemZengin\",\n",
    "    497244729: \"497244729\",\n",
    "    4289546317: \"4289546317\",\n",
    "    4685414552: \"4685414552\",\n",
    "    1128697424: \"@bir_nefer19\",\n",
    "    2363435375: \"@S_Luleci\",\n",
    "    1559824820: \"@7171eliflal\",\n",
    "    2292167660: \"Not Found\",\n",
    "    1132163245: \"@hzlandrc\",\n",
    "    422861505: \"@ekrem_imamoglu\",\n",
    "    945355840084742144: \"@mustafaaksutr\",\n",
    "    3297484329: \"@TC_Seri\",\n",
    "    2419895447: \"@bayramaygun2\",\n",
    "    2973073341: \"@cevreormanorgtr\",\n",
    "    2419895447: \"@bayramaygun2\",\n",
    "\n",
    "}\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/c\n",
    "\n",
    "# Create an empty dictionary to store user mentions and their counts\n",
    "user_mentions = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['user_mentions']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split user mentions by comma\n",
    "                mentions = row[1:-1].split(',')\n",
    "                mentions = [mention.strip() for mention in mentions if mention.strip() != \"\"]\n",
    "                # Iterate over each user mention\n",
    "                for mention in mentions:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    mention = mention.strip().lower()[1:-1]\n",
    "\n",
    "                    if mention.isdigit():  # Check if the mention is a numeric ID\n",
    "                        mention_id = int(mention)\n",
    "                        if mention_id in id_to_handle:\n",
    "                            mention = id_to_handle[mention_id]\n",
    "                        else:\n",
    "                            mention = mention  # If the mention is not a numeric ID, keep it as it is\n",
    "\n",
    "                    # Increment the count for the user mention in the dictionary\n",
    "                    if mention in user_mentions:\n",
    "                        user_mentions[mention] += 1\n",
    "                    else:\n",
    "                        user_mentions[mention] = 1\n",
    "\n",
    "# Sort the user mentions dictionary by count in descending order and get the top 100\n",
    "#top_100_mentions = sorted(user_mentions.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user mentions and their counts into separate lists\n",
    "mentions_list = [mention[0] for mention in top_100_mentions]\n",
    "counts_list = [mention[1] for mention in top_100_mentions]\n",
    "\n",
    "# Sort the user_mentions dictionary by count in descending order and get the top 100\n",
    "top_100_user_mentions = sorted(user_mentions.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user mentions and their counts into separate lists\n",
    "user_mentions_list = [mention[0] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "counts_list = [mention[1] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_mentions_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 100 User Mentions and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "#plt.savefig(\"top100usermentions.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentions_list = [mention[0] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "counts_list = [mention[1] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_mentions_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 100 User Mentions and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "plt.savefig(\"top100usermentions.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EYE-BALL BYLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX/TwitterReleases/InformationOperations/202006/hashed_2020_05_turkey_052020_turkey_052020_tweets_csv_hashed.zip\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['tweet_client_name']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    client_name = row.strip()\n",
    "\n",
    "                    # Increment the count for the tweet client in the dictionary\n",
    "                    if client_name in tweet_clients:\n",
    "                        tweet_clients[client_name] += 1\n",
    "                    else:\n",
    "                        tweet_clients[client_name] = 1\n",
    "\n",
    "# Sort the tweet clients dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_clients = sorted(tweet_clients.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet clients and their counts into separate lists\n",
    "tweet_clients_list = [client[0] for client in top_100_tweet_clients][::-1]  # Reverse the list\n",
    "counts_list = [client[1] for client in top_100_tweet_clients][::-1]  # Reverse the list\n",
    "\n",
    "\n",
    "\n",
    "client_name_to_find = \"bylockreality.com Auto Tweet\"\n",
    "if client_name_to_find in tweet_clients:\n",
    "    count_by_client = tweet_clients[client_name_to_find]\n",
    "    print(f\"Count of tweets by '{client_name_to_find}': {count_by_client}\")\n",
    "else:\n",
    "    print(f\"Client '{client_name_to_find}' not found in the tweet clients.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_texts = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_client_name\" equal to \"bylockreality.com Auto Tweet\"\n",
    "            filtered_df = df[df['tweet_client_name'] == 'bylockreality.com Auto Tweet']\n",
    "\n",
    "            for row in filtered_df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "                    print(tweet_text)  # Print the \"tweet_text\" from \"bylockreality.com Auto Tweet\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tweetss from specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_texts = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"userid\" equal to \"1628824092\"\n",
    "            filtered_df = df[df['tweet_client_name'] == 'erased14500']\n",
    "\n",
    "            for row in filtered_df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "                    print(tweet_text)  # Print the \"tweet_text\" from \"bylockreality.com Auto Tweet\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tweets from specific time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty list to store tweet texts\n",
    "tweet_texts = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_time\" equal to \"2016-08-30 08:11\"\n",
    "            filtered_df = df[df['tweet_time'] == '2016-08-30 08:11']\n",
    "\n",
    "            for row in filtered_df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "                    tweet_texts.append(tweet_text)  # Add the \"tweet_text\" to the list\n",
    "\n",
    "if tweet_texts:\n",
    "    for tweet_text in tweet_texts:\n",
    "        print(tweet_text)\n",
    "else:\n",
    "    print(\"No tweets found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_texts = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            for row in df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "\n",
    "                    # Increment the count for the tweet text in the dictionary\n",
    "                    if tweet_text in tweet_texts:\n",
    "                        tweet_texts[tweet_text] += 1\n",
    "                    else:\n",
    "                        tweet_texts[tweet_text] = 1\n",
    "\n",
    "# Sort the tweet texts dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_texts = sorted(tweet_texts.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet texts and their counts into separate lists\n",
    "tweet_texts_list = [tweet[0] for tweet in top_100_tweet_texts][::-1]  # Reverse the list\n",
    "counts_list = [tweet[1] for tweet in top_100_tweet_texts][::-1]  # Reverse the list\n",
    "\n",
    "if tweet_texts:\n",
    "    for tweet_text in tweet_texts:\n",
    "        print(tweet_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top 100 reply users tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a list to store user replies\n",
    "user_replies = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            # Filter tweets that are replies and have a valid 'in_reply_to_userid'\n",
    "            replies = df[df['in_reply_to_userid'].notnull()]['in_reply_to_userid'].tolist()\n",
    "            # Extend the user_replies list with the extracted replies\n",
    "            user_replies.extend(replies)\n",
    "\n",
    "# Count the occurrences of each user ID in the user_replies list\n",
    "user_reply_counts = {}\n",
    "for user_id in user_replies:\n",
    "    if user_id in user_reply_counts:\n",
    "        user_reply_counts[user_id] += 1\n",
    "    else:\n",
    "        user_reply_counts[user_id] = 1\n",
    "\n",
    "# Sort the user_reply_counts dictionary by count in descending order and get the top 100\n",
    "top_100_user_replies = sorted(user_reply_counts.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user IDs and their counts into separate lists\n",
    "user_id_list = [user_id[0] for user_id in top_100_user_replies][::-1]  # Reverse the list\n",
    "counts_list = [user_id[1] for user_id in top_100_user_replies][::-1]  # Reverse the list\n",
    "\n",
    "# Now, let's print the tweets of these top 100 accounts\n",
    "for user_id in user_id_list:\n",
    "    # Loop through the CSV files again to find tweets from the user_id\n",
    "    with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "        for member in zObject.namelist():\n",
    "            if member.endswith(\".csv\"):\n",
    "                df = pd.read_csv(zObject.open(member))\n",
    "                # Filter tweets from the current user_id\n",
    "                user_tweets = df[df['userid'] == user_id]\n",
    "                # Print the tweet text\n",
    "                for tweet_text in user_tweets['tweet_text']:\n",
    "                    print(tweet_text)\n",
    "                # You can choose to print additional information from the tweets, if needed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top 100 client tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            for row in df['tweet_client_name']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    client_name = row.strip()\n",
    "\n",
    "                    # Increment the count for the tweet client in the dictionary\n",
    "                    if client_name in tweet_clients:\n",
    "                        tweet_clients[client_name] += 1\n",
    "                    else:\n",
    "                        tweet_clients[client_name] = 1\n",
    "\n",
    "# Sort the tweet clients dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_clients = sorted(tweet_clients.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet clients and their counts into separate lists\n",
    "tweet_clients_list = [client[0] for client in top_100_tweet_clients]\n",
    "counts_list = [client[1] for client in top_100_tweet_clients]\n",
    "\n",
    "# Create an empty list to store the tweet texts for the top 100 clients\n",
    "tweet_texts = []\n",
    "\n",
    "# Loop through each CSV file again and extract tweet text for each client\n",
    "for member in zObject.namelist():\n",
    "    if member.endswith(\".csv\"):\n",
    "        df = pd.read_csv(zObject.open(member))\n",
    "        for index, row in df.iterrows():\n",
    "            client_name = row['tweet_client_name'].strip()\n",
    "            tweet_text = row['tweet_text'].strip()\n",
    "            \n",
    "            # Check if the client_name matches any of the top 100 clients\n",
    "            if client_name in tweet_clients_list:\n",
    "                tweet_texts.append(tweet_text)\n",
    "\n",
    "# Now you have all the tweet texts for the top 100 tweet clients in the `tweet_texts` list\n",
    "# You can do further processing or analysis on this list as needed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top 100 clients tweet with erased apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients = {}\n",
    "\n",
    "# Create an empty list to store all tweet texts\n",
    "tweet_texts = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file and read them into a list\n",
    "    csv_files = [member for member in zObject.namelist() if member.endswith(\".csv\")]\n",
    "\n",
    "    for member in csv_files:\n",
    "        df = pd.read_csv(zObject.open(member))\n",
    "        for index, row in df.iterrows():\n",
    "            client_name = row['tweet_client_name'].strip()\n",
    "            tweet_text = row['tweet_text'].strip()\n",
    "\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(client_name) and pd.notnull(tweet_text):\n",
    "                # Increment the count for the tweet client in the dictionary\n",
    "                if client_name in tweet_clients:\n",
    "                    tweet_clients[client_name] += 1\n",
    "                else:\n",
    "                    tweet_clients[client_name] = 1\n",
    "\n",
    "                # Check if the client_name matches any of the top 100 clients\n",
    "                if client_name in tweet_clients_list:\n",
    "                    tweet_texts.append(tweet_text)\n",
    "\n",
    "# Sort the tweet clients dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_clients = sorted(tweet_clients.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet clients and their counts into separate lists\n",
    "tweet_clients_list = [client[0] for client in top_100_tweet_clients]\n",
    "counts_list = [client[1] for client in top_100_tweet_clients]\n",
    "\n",
    "# Now you have all the tweet texts for the top 100 tweet clients in the `tweet_texts` list\n",
    "# You can do further processing or analysis on this list as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients = {}\n",
    "\n",
    "# Create an empty list to store all tweet texts\n",
    "tweet_texts = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file and read them into a list\n",
    "    csv_files = [member for member in zObject.namelist() if member.endswith(\".csv\")]\n",
    "\n",
    "    for member in csv_files:\n",
    "        df = pd.read_csv(zObject.open(member))\n",
    "        for index, row in df.iterrows():\n",
    "            client_name = row['tweet_client_name'].strip()\n",
    "            tweet_text = row['tweet_text'].strip()\n",
    "\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(client_name) and pd.notnull(tweet_text):\n",
    "                # Increment the count for the tweet client in the dictionary\n",
    "                if client_name in tweet_clients:\n",
    "                    tweet_clients[client_name] += 1\n",
    "                else:\n",
    "                    tweet_clients[client_name] = 1\n",
    "\n",
    "                # Check if the client_name matches any of the top 100 clients\n",
    "                if client_name in tweet_clients_list:\n",
    "                    tweet_texts.append(tweet_text)\n",
    "\n",
    "# Sort the tweet clients dictionary by count in descending order and get the top 100\n",
    "top_100_tweet_clients = sorted(tweet_clients.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the tweet clients and their counts into separate lists\n",
    "tweet_clients_list = [client[0] for client in top_100_tweet_clients]\n",
    "counts_list = [client[1] for client in top_100_tweet_clients]\n",
    "\n",
    "# Print the top 100 tweet clients and their counts\n",
    "for i, client in enumerate(tweet_clients_list):\n",
    "    print(f\"{i + 1}. {client}: {counts_list[i]}\")\n",
    "\n",
    "# Now you have all the tweet texts for the top 100 tweet clients in the `tweet_texts` list\n",
    "# You can do further processing or analysis on this list as needed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erased Clients names/counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_clients_count = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_client_name\" containing \"erased\"\n",
    "            filtered_df = df[df['tweet_client_name'].str.contains('erased', case=False, na=False)]\n",
    "\n",
    "            # Count the occurrences of each tweet client name and store it in the dictionary\n",
    "            for client_name in filtered_df['tweet_client_name']:\n",
    "                if client_name in tweet_clients_count:\n",
    "                    tweet_clients_count[client_name] += 1\n",
    "                else:\n",
    "                    tweet_clients_count[client_name] = 1\n",
    "\n",
    "# Print the tweet client names and their corresponding tweet counts\n",
    "if len(tweet_clients_count) > 0:\n",
    "    for client_name, count in tweet_clients_count.items():\n",
    "        print(f\"Tweet Client Name: {client_name}, Tweet Count: {count}\")\n",
    "else:\n",
    "    print(\"None found.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bismillah network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import glob\n",
    "import zipfile\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store user IDs and their counts\n",
    "user_ids = {}\n",
    "\n",
    "# Create an empty directed graph (network) to store the user mentions\n",
    "G = nx.DiGraph()  # Changed to DiGraph to store directed edges\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            # Read the CSV file into a pandas DataFrame\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if pd.notnull(row['userid']) and 'Twitter for' in row['tweet_client_name']:\n",
    "        user_id = row['userid']\n",
    "        mentions = ast.literal_eval(row['user_mentions']) if pd.notnull(row['user_mentions']) else []  # Parse the string and create a list\n",
    "        for mention in mentions:\n",
    "            if user_id != mention and mention in df['userid'].values:\n",
    "                # Check if the mentioned user exists in the DataFrame\n",
    "                if user_id not in G.nodes:\n",
    "                    G.add_node(user_id)\n",
    "\n",
    "                if mention not in G.nodes:\n",
    "                    G.add_node(mention)\n",
    "\n",
    "                if G.has_edge(user_id, mention):\n",
    "                    # Increment the edge weight if the edge exists\n",
    "                    G[user_id][mention]['weight'] += 1\n",
    "                else:\n",
    "                    # Add a new edge with weight 1 if the edge doesn't exist\n",
    "                    G.add_edge(user_id, mention, weight=1)\n",
    "\n",
    "                # Increment the count for the user ID in the dictionary\n",
    "                if user_id in user_ids:\n",
    "                    user_ids[user_id] += 1\n",
    "                else:\n",
    "                    user_ids[user_id] = 1\n",
    "\n",
    "# Convert the user_ids dictionary to a list of tuples\n",
    "user_ids_list = list(user_ids.items())\n",
    "\n",
    "# Sort the user IDs list by count in descending order\n",
    "user_ids_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract the user IDs with their counts into separate lists\n",
    "user_ids_only = [user[0] for user in user_ids_list]\n",
    "counts_only = [user[1] for user in user_ids_list]\n",
    "\n",
    "# Create a new subgraph containing only the users who mentioned each other\n",
    "subgraph = G.subgraph(user_ids_only)\n",
    "\n",
    "# Perform further operations on the subgraph as needed\n",
    "# For example, you can visualize the subgraph:\n",
    "\n",
    "if len(G.edges) == 0:\n",
    "    print(\"No edges in the graph.\")\n",
    "    \n",
    "nx.draw(subgraph, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new subgraph containing only the users who mentioned each other\n",
    "subgraph = G.subgraph(user_ids_only)\n",
    "\n",
    "# Print the number of nodes in the subgraph\n",
    "print(\"Number of nodes in the subgraph:\", subgraph.number_of_nodes())\n",
    "\n",
    "# Perform further operations on the subgraph as needed\n",
    "# For example, you can visualize the subgraph:\n",
    "\n",
    "if len(G.edges) == 0:\n",
    "    print(\"No edges in the graph.\")\n",
    "    \n",
    "nx.draw(subgraph, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new subgraph containing only the users who mentioned each other\n",
    "subgraph = G.subgraph(user_ids_only)\n",
    "\n",
    "# Print the number of nodes and edges in the subgraph\n",
    "print(\"Number of nodes in the subgraph:\", subgraph.number_of_nodes())\n",
    "print(\"Number of edges in the subgraph:\", subgraph.number_of_edges())\n",
    "\n",
    "# Print the users who mentioned each other and how many times\n",
    "for source, target, data in subgraph.edges(data=True):\n",
    "    print(f\"{source} mentioned {target} {data['weight']} times.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import glob\n",
    "import zipfile\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store user IDs and their counts\n",
    "user_ids = {}\n",
    "\n",
    "# Create an empty directed graph (network) to store the user mentions\n",
    "G = nx.DiGraph()  # Changed to DiGraph to store directed edges\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            # Read the CSV file into a pandas DataFrame\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "# Convert relevant columns to lists\n",
    "user_ids_list = df['userid'].dropna().tolist()\n",
    "mentions_list = df['user_mentions'].dropna().tolist()\n",
    "\n",
    "for user_id, mentions_str in zip(user_ids_list, mentions_list):\n",
    "    mentions = ast.literal_eval(mentions_str) if mentions_str else []\n",
    "    for mention in mentions:\n",
    "        if user_id != mention and mention in user_ids_list:\n",
    "            if user_id not in G:\n",
    "                G.add_node(user_id)\n",
    "            if mention not in G:\n",
    "                G.add_node(mention)\n",
    "            if G.has_edge(user_id, mention):\n",
    "                # Increment the edge weight if the edge exists\n",
    "                G[user_id][mention]['weight'] += 1\n",
    "            else:\n",
    "                # Add a new edge with weight 1 if the edge doesn't exist\n",
    "                G.add_edge(user_id, mention, weight=1)\n",
    "\n",
    "            # Increment the count for the user ID in the dictionary\n",
    "            user_ids[user_id] = user_ids.get(user_id, 0) + 1\n",
    "\n",
    "# Convert the user_ids dictionary to a list of tuples\n",
    "user_ids_list = list(user_ids.items())\n",
    "\n",
    "# Sort the user IDs list by count in descending order\n",
    "user_ids_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract the user IDs with their counts into separate lists\n",
    "user_ids_only = [user[0] for user in user_ids_list]\n",
    "counts_only = [user[1] for user in user_ids_list]\n",
    "\n",
    "# Create a new subgraph containing only the users who mentioned each other\n",
    "subgraph = G.subgraph(user_ids_only)\n",
    "\n",
    "# Perform further operations on the subgraph as needed\n",
    "# For example, you can visualize the subgraph:\n",
    "\n",
    "if len(G.edges) == 0:\n",
    "    print(\"No edges in the graph.\")\n",
    "\n",
    "nx.draw(subgraph, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of nodes and edges in the graph\n",
    "print(\"Number of nodes:\", subgraph.number_of_nodes())\n",
    "print(\"Number of edges:\", subgraph.number_of_edges())\n",
    "\n",
    "# Display who mentioned whom\n",
    "print(\"Who mentioned whom:\")\n",
    "for user_id, mention in subgraph.edges():\n",
    "    weight = subgraph[user_id][mention]['weight']\n",
    "    print(f\"{user_id} mentioned {mention} {weight} time(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erased accounts code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients_count = {}\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags_count = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_client_name\" containing \"erased\"\n",
    "            filtered_df = df[df['tweet_client_name'].str.contains('erased', case=False, na=False)]\n",
    "\n",
    "            # Count the occurrences of each tweet client name and store it in the dictionary\n",
    "            for client_name in filtered_df['tweet_client_name']:\n",
    "                if client_name in tweet_clients_count:\n",
    "                    tweet_clients_count[client_name] += 1\n",
    "                else:\n",
    "                    tweet_clients_count[client_name] = 1\n",
    "\n",
    "            # Extract hashtags from the tweet texts and count their occurrences\n",
    "            for tweet_text in filtered_df['tweet_text']:\n",
    "                hashtags = re.findall(r'#\\w+', tweet_text)\n",
    "                for hashtag in hashtags:\n",
    "                    if hashtag in hashtags_count:\n",
    "                        hashtags_count[hashtag] += 1\n",
    "                    else:\n",
    "                        hashtags_count[hashtag] = 1\n",
    "\n",
    "# Print the tweet client names and their corresponding tweet counts\n",
    "if len(tweet_clients_count) > 0:\n",
    "    for client_name, count in tweet_clients_count.items():\n",
    "        print(f\"Tweet Client Name: {client_name}, Tweet Count: {count}\")\n",
    "else:\n",
    "    print(\"No tweet clients found.\")\n",
    "\n",
    "# Print the hashtags and their corresponding tweet counts\n",
    "if len(hashtags_count) > 0:\n",
    "    for hashtag, count in hashtags_count.items():\n",
    "        print(f\"Hashtag: {hashtag}, Count: {count}\")\n",
    "else:\n",
    "    print(\"No hashtags found.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top100 erased app hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients_count = {}\n",
    "\n",
    "# Create a list to store all hashtags\n",
    "all_hashtags = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_client_name\" containing \"erased\"\n",
    "            filtered_df = df[df['tweet_client_name'].str.contains('erased', case=False, na=False)]\n",
    "\n",
    "            # Count the occurrences of each tweet client name and store it in the dictionary\n",
    "            for client_name in filtered_df['tweet_client_name']:\n",
    "                if client_name in tweet_clients_count:\n",
    "                    tweet_clients_count[client_name] += 1\n",
    "                else:\n",
    "                    tweet_clients_count[client_name] = 1\n",
    "\n",
    "            # Extract hashtags from the tweet texts and add them to the list\n",
    "            for tweet_text in filtered_df['tweet_text']:\n",
    "                hashtags = re.findall(r'#\\w+', tweet_text)\n",
    "                all_hashtags.extend(hashtags)\n",
    "\n",
    "# Count the occurrences of each hashtag and get the top 100 most used hashtags\n",
    "top_100_hashtags = Counter(all_hashtags).most_common(100)\n",
    "\n",
    "# Print the tweet client names and their corresponding tweet counts\n",
    "if len(tweet_clients_count) > 0:\n",
    "    for client_name, count in tweet_clients_count.items():\n",
    "        print(f\"Tweet Client Name: {client_name}, Tweet Count: {count}\")\n",
    "else:\n",
    "    print(\"No tweet clients found.\")\n",
    "\n",
    "# Print the top 100 most used hashtags\n",
    "if len(top_100_hashtags) > 0:\n",
    "    for hashtag, count in top_100_hashtags:\n",
    "        print(f\"Hashtag: {hashtag}, Count: {count}\")\n",
    "else:\n",
    "    print(\"No hashtags found.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tweets from top erased app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_texts = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"userid\" equal to \"1628824092\"\n",
    "            filtered_df = df[df['tweet_client_name'] == 'erased15418350']\n",
    "\n",
    "            for row in filtered_df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "                    print(tweet_text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet clients and their counts\n",
    "tweet_clients_count = {}\n",
    "\n",
    "# Create a list to store all hashtags\n",
    "all_hashtags = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_client_name\" containing \"erased\"\n",
    "            filtered_df = df[df['tweet_client_name'].isin(['ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d'])]\n",
    "\n",
    "            # Count the occurrences of each tweet client name and store it in the dictionary\n",
    "            for client_name in filtered_df['tweet_client_name']:\n",
    "                if client_name in tweet_clients_count:\n",
    "                    tweet_clients_count[client_name] += 1\n",
    "                else:\n",
    "                    tweet_clients_count[client_name] = 1\n",
    "\n",
    "            # Extract hashtags from the tweet texts and add them to the list\n",
    "            for tweet_text in filtered_df['tweet_text']:\n",
    "                hashtags = re.findall(r'#\\w+', tweet_text)\n",
    "                all_hashtags.extend(hashtags)\n",
    "\n",
    "# Count the occurrences of each hashtag and get the top 100 most used hashtags\n",
    "top_100_hashtags = Counter(all_hashtags).most_common(100)\n",
    "\n",
    "# Print the tweet client names and their corresponding tweet counts\n",
    "if len(tweet_clients_count) > 0:\n",
    "    for client_name, count in tweet_clients_count.items():\n",
    "        print(f\"Tweet Client Name: {client_name}, Tweet Count: {count}\")\n",
    "else:\n",
    "    print(\"No tweet clients found.\")\n",
    "\n",
    "# Print the top 100 most used hashtags\n",
    "if len(top_100_hashtags) > 0:\n",
    "    for hashtag, count in top_100_hashtags:\n",
    "        print(f\"Hashtag: {hashtag}, Count: {count}\")\n",
    "else:\n",
    "    print(\"No hashtags found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_texts = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            \n",
    "            filtered_df = df[df['tweet_client_name'].isin(['ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d'])]\n",
    "\n",
    "            for row in filtered_df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "                    print(tweet_text)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vuk359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty list to store tweet texts\n",
    "tweet_texts = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_time\" equal to \"2016-08-30 08:11\"\n",
    "            filtered_df = df[df['hashtags'] == 'vuk359']\n",
    "\n",
    "            for row in filtered_df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "                    tweet_texts.append(tweet_text)  # Add the \"tweet_text\" to the list\n",
    "\n",
    "if tweet_texts:\n",
    "    for tweet_text in tweet_texts:\n",
    "        print(tweet_text)\n",
    "else:\n",
    "    print(\"No tweets found.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clients that used the hashtag 1416 ylsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet client names and their counts\n",
    "tweet_client_names = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"hashtags\" column containing '1416ylsy'\n",
    "            filtered_df = df[df['hashtags'].str.contains('1416ylsy', na=False)]\n",
    "\n",
    "            for client_name in filtered_df['tweet_client_name']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(client_name):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    client_name = client_name.strip()\n",
    "\n",
    "                    # Update the count in the dictionary\n",
    "                    if client_name in tweet_client_names:\n",
    "                        tweet_client_names[client_name] += 1\n",
    "                    else:\n",
    "                        tweet_client_names[client_name] = 1\n",
    "\n",
    "# Print the tweet client names and their counts\n",
    "for client_name, count in tweet_client_names.items():\n",
    "    print(f\"{client_name}: {count}\")\n",
    "\n",
    "# Plot the counts as a bar chart\n",
    "plt.bar(tweet_client_names.keys(), tweet_client_names.values())\n",
    "plt.xlabel('Tweet Client Names')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dictionary by count in descending order\n",
    "sorted_tweet_client_names = dict(sorted(tweet_client_names.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Print the tweet client names and their counts\n",
    "for client_name, count in sorted_tweet_client_names.items():\n",
    "    print(f\"{client_name}: {count}\")\n",
    "\n",
    "# Plot the counts as a bar chart with gold color and ordered counts\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(sorted_tweet_client_names.keys(), sorted_tweet_client_names.values(), width=0.6, color='gold')\n",
    "\n",
    "plt.xlabel('Tweet Client Names')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Tweet Client Names and Their Counts for #1416ylsy')\n",
    "\n",
    "# Control the x-axis tick positions and labels to add more spacing between labels\n",
    "plt.xticks(range(len(sorted_tweet_client_names)), sorted_tweet_client_names.keys())\n",
    "\n",
    "# Increase the font size for the tweet client names\n",
    "plt.gca().xaxis.set_tick_params(labelsize=11)\n",
    "\n",
    "\n",
    "plt.savefig(\"1416ylsy.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 50 account creation dates from the 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet client names and their counts\n",
    "tweet_client_names = {}\n",
    "tweet_clients_to_userids = {}  # Dictionary to store tweet_client_name -> list of userids\n",
    "userids_to_creation_dates = {}  # New dictionary to store userid -> account_creation_date\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"hashtags\" column containing '1416ylsy'\n",
    "            filtered_df = df[df['hashtags'].str.contains('1416ylsy', na=False)]\n",
    "\n",
    "            for index, row in filtered_df.iterrows():\n",
    "                client_name = row['tweet_client_name']\n",
    "                userid = row['userid']\n",
    "                creation_date = row['account_creation_date']\n",
    "\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(client_name) and pd.notnull(userid) and pd.notnull(creation_date):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    client_name = client_name.strip()\n",
    "                    userid = str(userid)\n",
    "                    creation_date = str(creation_date)\n",
    "\n",
    "                    # Update the count in the dictionaries\n",
    "                    if client_name in tweet_client_names:\n",
    "                        tweet_client_names[client_name] += 1\n",
    "                        tweet_clients_to_userids[client_name].append(userid)\n",
    "                    else:\n",
    "                        tweet_client_names[client_name] = 1\n",
    "                        tweet_clients_to_userids[client_name] = [userid]\n",
    "\n",
    "                    userids_to_creation_dates[userid] = creation_date\n",
    "\n",
    "# Sort the dictionary by count in descending order\n",
    "sorted_tweet_client_names = dict(sorted(tweet_client_names.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Print the tweet client names and their counts\n",
    "for client_name, count in sorted_tweet_client_names.items():\n",
    "    print(f\"{client_name}: {count}\")\n",
    "\n",
    "# Print the \"userid\"s for each \"tweet_client_name\"\n",
    "for client_name, userids in tweet_clients_to_userids.items():\n",
    "    print(f\"UserIDs for {client_name}: {userids}\")\n",
    "\n",
    "# Print the account creation dates for each \"userid\"\n",
    "for userid, creation_date in userids_to_creation_dates.items():\n",
    "    print(f\"UserID: {userid}, Account Creation Date: {creation_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty list to store user creation dates\n",
    "user_creation_dates = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            \n",
    "            # Filter rows with \"hashtags\" column containing '1416ylsy'\n",
    "            filtered_df = df[df['hashtags'].str.contains('1416ylsy', na=False)]\n",
    "            \n",
    "            # Iterate over the filtered dataframe\n",
    "            for index, row in filtered_df.iterrows():\n",
    "                user_id = row['userid']\n",
    "                creation_date = row['account_creation_date']\n",
    "                \n",
    "                # Append the creation date to the list\n",
    "                user_creation_dates.append(creation_date)\n",
    "\n",
    "# Count the occurrences of each creation date\n",
    "date_counts = pd.Series(user_creation_dates).value_counts()\n",
    "\n",
    "# Select the top 50 creation dates\n",
    "top_50_dates = date_counts.head(50)\n",
    "\n",
    "# Plot the top 50 creation dates\n",
    "plt.bar(top_50_dates.index, top_50_dates.values)\n",
    "plt.xlabel(\"Creation Dates\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 50 User Creation Dates\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(top_50_dates.index, top_50_dates.values, color='gold')\n",
    "\n",
    "plt.xlabel(\"Creation Dates\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top User Creation Dates For User IDs That Tweeted #1416ylys\")  # Updated title\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig(\"creationdates1416ylsy.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for creation_date, count in user_creation_dates_counts.items():\n",
    "    print(f\"Creation Date: {creation_date}, Count: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top hashtags for 7 apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# List of tweet_client_name values to filter\n",
    "tweet_client_names = [\"erased15418350\", 'ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d', \"asdasd asd ask asd\"]\n",
    "\n",
    "# Create an empty list to store the filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_client_name\" matching specific names\n",
    "            filtered_df = df[df['tweet_client_name'].isin(tweet_client_names)]\n",
    "\n",
    "            # Extract the hashtags from the filtered DataFrame\n",
    "            hashtags = filtered_df['hashtags'].tolist()\n",
    "\n",
    "            # Format and make hashtags case-insensitive\n",
    "            formatted_hashtags = []\n",
    "            for hashtag_list in hashtags:\n",
    "                formatted_hashtags.extend([\"#\" + tag.strip().lower() for tag in hashtag_list.strip(\"[]\").split(\",\")])\n",
    "\n",
    "            # Add the formatted hashtags to the filtered_data list\n",
    "            filtered_data.extend(formatted_hashtags)\n",
    "\n",
    "# Count the occurrences of each hashtag\n",
    "hashtag_counts = {}\n",
    "for hashtag in filtered_data:\n",
    "    if hashtag in hashtag_counts:\n",
    "        hashtag_counts[hashtag] += 1\n",
    "    else:\n",
    "        hashtag_counts[hashtag] = 1\n",
    "\n",
    "# Sort the hashtags by count in descending order\n",
    "sorted_hashtags = sorted(hashtag_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "# Extract the top 100 hashtags and their counts\n",
    "top_50_hashtags = sorted_hashtags[:50]\n",
    "hashtags_list, counts_list = zip(*top_50_hashtags)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(hashtags_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Hashtag')\n",
    "plt.title('Top 50 Hashtags and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "#plt.savefig(\"top50operations.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the list of top hashtags and their counts\n",
    "top_50_hashtags = sorted_hashtags[:50][::-1]\n",
    "hashtags_list, counts_list = zip(*top_50_hashtags)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(hashtags_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Hashtag')\n",
    "plt.title('Top 50 Hashtags from 7 Suspected Accounts and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Function to add count labels on top of each bar\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "#plt.savefig(\"top50operations.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top mentions for 7 apps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# List of tweet_client_name values to filter\n",
    "tweet_client_names = [\"erased15418350\", 'ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d', \"asdasd asd ask asd\"]\n",
    "\n",
    "# Create an empty list to store the filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"tweet_client_name\" matching specific names\n",
    "            filtered_df = df[df['tweet_client_name'].isin(tweet_client_names)]\n",
    "\n",
    "            # Extract the user mentions from the filtered DataFrame\n",
    "            user_mentions = filtered_df['user_mentions'].tolist()\n",
    "\n",
    "            # Format and make user mentions case-insensitive\n",
    "            formatted_user_mentions = []\n",
    "            for mention_list in user_mentions:\n",
    "                if mention_list.strip():  # Check if the mention list is not empty or contains only spaces\n",
    "                    formatted_mentions = [mention.strip().lower() for mention in mention_list.strip(\"[]\").split(\",\")]\n",
    "                    formatted_user_mentions.extend([mention for mention in formatted_mentions if mention])  # Exclude empty or whitespace-only mentions\n",
    "\n",
    "            # Match user IDs with user handles\n",
    "            id_to_handle = {\n",
    "    68034431: \"@RTErdogan\",\n",
    "    1628824092: \"@Akparti\",\n",
    "    155534196: \"@abdulhamitgul\",\n",
    "    3160777371: \"3160777371\",\n",
    "    272613386: \"@tcbestepe\",\n",
    "    236131165: \"@06melihgokcek\",\n",
    "    214017108: \"@dbdevletbahceli\",\n",
    "    244659700: \"244659700\",\n",
    "    1589135268: \"@Lokman_Erturk\",\n",
    "    737302248338952193: \"@BY\",\n",
    "    233614834: \"@bekirpakdemirli\",\n",
    "    161355169: \"@MHP_Bilgi\",\n",
    "    769869708359237632: \"@tcsavunma\",\n",
    "    18971997: \"@suleymansoylu\",\n",
    "    237451465: \"@kbbmustafaak\",\n",
    "    154140901: \"@kilicdarogluk\",\n",
    "    967087600426209281: \"@fahrettinaltun\",\n",
    "    255515879: \"@herkesicinCHP\",\n",
    "    254777933: \"@hasandogan\",\n",
    "    979992619362209792: \"@YildizFeti\",\n",
    "    194792183: \"@iletisim\",\n",
    "    1509778892: \"@gonulborann\",\n",
    "    762053863369302016: \"762053863369302016\",\n",
    "    1385680262: \"1385680262\",\n",
    "    810886674: \"@naci_agbal\",\n",
    "    895250727039369217: \"@fuatoktay\",\n",
    "    885222182: \"@BA_Yildirim\",\n",
    "    2261268656: \"2261268656\",\n",
    "    704390419451387904: \"704390419451387904\",\n",
    "    526832991: \"@muratcan373\",\n",
    "    751570558454751232: \"751570558454751232\",\n",
    "    902503200728731649: \"@iyiparti\",\n",
    "    937058248133431296: \"937058248133431296\",\n",
    "    369515882: \"@omerrcelik\",\n",
    "    1321952677: \"@mkulunk\",\n",
    "    550409055: \"@akbasmarkt\",\n",
    "    226219067: \"@MustafaSentop\",\n",
    "    34350322: \"@NumanKurtulmus\",\n",
    "    181567076: \"@Ahmet_Davutoglu\",\n",
    "    564749194: \"@avabdullahguler\",\n",
    "    4077072555: \"@_Tevazu_\",\n",
    "    204277565: \"@ziyaselcuk\",\n",
    "    153772652: \"@ikalin1\",\n",
    "    772694821840519168: \"@TSKGnkur\",\n",
    "    915867855090012160: \"@EmineErdogan\",\n",
    "    2827024772: \"2827024772\",\n",
    "    501024041: \"@receparac06\",\n",
    "    2871475105: \"2871475105\",\n",
    "    2309922296: \"2309922296\",\n",
    "    466757008: \"@ayseucar5\",\n",
    "    2693953496: \"@SemaAlfat\",\n",
    "    201339405: \"@turanbulent\",\n",
    "    1579982719: \"@AbiSayn\",\n",
    "    118447677: \"118447677\",\n",
    "    1482806160: \"@Yettingari_la\",\n",
    "    115216315: \"@yilmaztunc\",\n",
    "    397106208: \"@TheCimbomFacts\",\n",
    "    378802752: \"378802752\",\n",
    "    289435070: \"@ikiagustos\",\n",
    "    207085169: \"@mehmedmus\",\n",
    "    1495932654: \"@Djlaz1969Fevzi\",\n",
    "    609063409: \"@filiz175\",\n",
    "    2347061250: \"@delideli_0618_\",\n",
    "    182317200: \"@vekilince\",\n",
    "    765897180553043968: \"@erayyyNihal\",\n",
    "    2386809223: \"@tasdemir_cemile\",\n",
    "    229515050: \"@eczozgurozel\",\n",
    "    1690041488: \"@benstandart\",\n",
    "    2638260543: \"@SirMuratPL\",\n",
    "    3555190636: \"@EvitanNeslihan\",\n",
    "    1847174592: \"@Fatoss_ata\",\n",
    "    876521220791029760: \"876521220791029760\",\n",
    "    1056879184365142016: \"1056879184365142016\",\n",
    "    1899851310: \"@r__lcayirmeral\",\n",
    "    590346965: \"@meral_aksener\",\n",
    "    90854551: \"@nacibostanci\",\n",
    "    461305047: \"@TBMMGenelKurulu\",\n",
    "    293395910: \"@bekiservet\",\n",
    "    1421299758: \"@mehmetucum\",\n",
    "    744924164: \"@AvOzlemZengin\",\n",
    "    497244729: \"497244729\",\n",
    "    4289546317: \"4289546317\",\n",
    "    4685414552: \"4685414552\",\n",
    "    1128697424: \"@bir_nefer19\",\n",
    "    2363435375: \"@S_Luleci\",\n",
    "    1559824820: \"@7171eliflal\",\n",
    "    2292167660: \"Not Found\",\n",
    "    1132163245: \"@hzlandrc\",\n",
    "    422861505: \"@ekrem_imamoglu\",\n",
    "    945355840084742144: \"@mustafaaksutr\",\n",
    "    3297484329: \"@TC_Seri\",\n",
    "    2419895447: \"@bayramaygun2\",\n",
    "    2973073341: \"@cevreormanorgtr\",\n",
    "    2419895447: \"@bayramaygun2\",\n",
    "            }\n",
    "\n",
    "            # Replace user IDs with user handles\n",
    "            user_handles = []\n",
    "            for mention in formatted_user_mentions:\n",
    "                try:\n",
    "                    user_id = int(mention[1:])\n",
    "                    handle = id_to_handle.get(user_id, mention)\n",
    "                except ValueError:\n",
    "                    handle = mention\n",
    "                user_handles.append(handle)\n",
    "\n",
    "            # Add the formatted user handles to the filtered_data list\n",
    "            filtered_data.extend(user_handles)\n",
    "\n",
    "# Count the occurrences of each user handle\n",
    "handle_counts = {}\n",
    "for handle in filtered_data:\n",
    "    if handle in handle_counts:\n",
    "        handle_counts[handle] += 1\n",
    "    else:\n",
    "        handle_counts[handle] = 1\n",
    "\n",
    "# Sort the user mentions by count in descending order\n",
    "sorted_mentions = sorted(handle_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract the top 50 user mentions and their counts\n",
    "top_50_mentions = sorted_mentions[:50]\n",
    "top_50_mentions = sorted(top_50_mentions, key=lambda x: x[1], reverse=True)  # Sort the top 50 mentions by count in descending order\n",
    "\n",
    "mentions_list, counts_list = zip(*top_50_mentions)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(15, 20))\n",
    "bars = plt.barh(range(len(mentions_list)), counts_list, height=0.7, color='gold')  # Use range(len(mentions_list)) for vertical ordering\n",
    "plt.yticks(range(len(mentions_list)), mentions_list)  # Set the y-tick labels to the mentions list\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to display the top mention at the top\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 50 User Mentions and Their Counts')\n",
    "plt.tight_layout()\n",
    "\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right')\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "id_to_handle = {\n",
    "    68034431: \"@RTErdogan\",\n",
    "    1628824092: \"@Akparti\",\n",
    "    155534196: \"@abdulhamitgul\",\n",
    "    3160777371: \"3160777371\",\n",
    "    272613386: \"@tcbestepe\",\n",
    "    236131165: \"@06melihgokcek\",\n",
    "    214017108: \"@dbdevletbahceli\",\n",
    "    244659700: \"244659700\",\n",
    "    1589135268: \"@Lokman_Erturk\",\n",
    "    737302248338952193: \"@BY\",\n",
    "    233614834: \"@bekirpakdemirli\",\n",
    "    161355169: \"@MHP_Bilgi\",\n",
    "    769869708359237632: \"@tcsavunma\",\n",
    "    18971997: \"@suleymansoylu\",\n",
    "    237451465: \"@kbbmustafaak\",\n",
    "    154140901: \"@kilicdarogluk\",\n",
    "    967087600426209281: \"@fahrettinaltun\",\n",
    "    255515879: \"@herkesicinCHP\",\n",
    "    254777933: \"@hasandogan\",\n",
    "    979992619362209792: \"@YildizFeti\",\n",
    "    194792183: \"@iletisim\",\n",
    "    1509778892: \"@gonulborann\",\n",
    "    762053863369302016: \"762053863369302016\",\n",
    "    1385680262: \"1385680262\",\n",
    "    810886674: \"@naci_agbal\",\n",
    "    895250727039369217: \"@fuatoktay\",\n",
    "    885222182: \"@BA_Yildirim\",\n",
    "    2261268656: \"2261268656\",\n",
    "    704390419451387904: \"704390419451387904\",\n",
    "    526832991: \"@muratcan373\",\n",
    "    751570558454751232: \"751570558454751232\",\n",
    "    902503200728731649: \"@iyiparti\",\n",
    "    937058248133431296: \"937058248133431296\",\n",
    "    369515882: \"@omerrcelik\",\n",
    "    1321952677: \"@mkulunk\",\n",
    "    550409055: \"@akbasmarkt\",\n",
    "    226219067: \"@MustafaSentop\",\n",
    "    34350322: \"@NumanKurtulmus\",\n",
    "    181567076: \"@Ahmet_Davutoglu\",\n",
    "    564749194: \"@avabdullahguler\",\n",
    "    4077072555: \"@_Tevazu_\",\n",
    "    204277565: \"@ziyaselcuk\",\n",
    "    153772652: \"@ikalin1\",\n",
    "    772694821840519168: \"@TSKGnkur\",\n",
    "    915867855090012160: \"@EmineErdogan\",\n",
    "    2827024772: \"2827024772\",\n",
    "    501024041: \"@receparac06\",\n",
    "    2871475105: \"2871475105\",\n",
    "    2309922296: \"2309922296\",\n",
    "    466757008: \"@ayseucar5\",\n",
    "    2693953496: \"@SemaAlfat\",\n",
    "    201339405: \"@turanbulent\",\n",
    "    1579982719: \"@AbiSayn\",\n",
    "    118447677: \"118447677\",\n",
    "    1482806160: \"@Yettingari_la\",\n",
    "    115216315: \"@yilmaztunc\",\n",
    "    397106208: \"@TheCimbomFacts\",\n",
    "    378802752: \"378802752\",\n",
    "    289435070: \"@ikiagustos\",\n",
    "    207085169: \"@mehmedmus\",\n",
    "    1495932654: \"@Djlaz1969Fevzi\",\n",
    "    609063409: \"@filiz175\",\n",
    "    2347061250: \"@delideli_0618_\",\n",
    "    182317200: \"@vekilince\",\n",
    "    765897180553043968: \"@erayyyNihal\",\n",
    "    2386809223: \"@tasdemir_cemile\",\n",
    "    229515050: \"@eczozgurozel\",\n",
    "    1690041488: \"@benstandart\",\n",
    "    2638260543: \"@SirMuratPL\",\n",
    "    3555190636: \"@EvitanNeslihan\",\n",
    "    1847174592: \"@Fatoss_ata\",\n",
    "    876521220791029760: \"876521220791029760\",\n",
    "    1056879184365142016: \"1056879184365142016\",\n",
    "    1899851310: \"@r__lcayirmeral\",\n",
    "    590346965: \"@meral_aksener\",\n",
    "    90854551: \"@nacibostanci\",\n",
    "    461305047: \"@TBMMGenelKurulu\",\n",
    "    293395910: \"@bekiservet\",\n",
    "    1421299758: \"@mehmetucum\",\n",
    "    744924164: \"@AvOzlemZengin\",\n",
    "    497244729: \"497244729\",\n",
    "    4289546317: \"4289546317\",\n",
    "    4685414552: \"4685414552\",\n",
    "    1128697424: \"@bir_nefer19\",\n",
    "    2363435375: \"@S_Luleci\",\n",
    "    1559824820: \"@7171eliflal\",\n",
    "    2292167660: \"Not Found\",\n",
    "    1132163245: \"@hzlandrc\",\n",
    "    422861505: \"@ekrem_imamoglu\",\n",
    "    945355840084742144: \"@mustafaaksutr\",\n",
    "    3297484329: \"@TC_Seri\",\n",
    "    2419895447: \"@bayramaygun2\",\n",
    "    2973073341: \"@cevreormanorgtr\",\n",
    "    2419895447: \"@bayramaygun2\", \n",
    "    301490933: \"@oktay_saral\",\n",
    "    46306298: \"@Gulnuray\",\n",
    "    70363441: \"@varank\",\n",
    "    2917691151: \"@AbbasGucluTR\",\n",
    "    366475101: \"@Yusuf__Tekin\",\n",
    "    200895896: \"@dkavranoglu\",\n",
    "    283080153: \"@ZeybekciNihat\",\n",
    "    418783013: \"@AyseTurkmenogl\",\n",
    "    1277286792: \"@huseyincamak\",\n",
    "    1019324490671640578: \"@TC_Basbakan\",\n",
    "    338523404: \"@ismailgunes64\",\n",
    "    1004673554930159616: \"@ala_refiki\",\n",
    "    1116716767114612736: \"@rt_erdogan\",\n",
    "    91248892: \"@lovenzyme\",\n",
    "    1003656757628030978: \"@mntomac\",\n",
    "    807261369686953984: \"@havvakaya61\",\n",
    "    1462055827: \"@yalcintaze\",\n",
    "    86949055: \"@Utokach\",\n",
    "    804784178755682304: \"@ylsy_1416\",\n",
    "    451343108: \"@fethigurer\",\n",
    "    1004371703387115524: \"@MagdurYlsy\",\n",
    "    805618923769040898: \"@UmitKarabiyik34\",\n",
    "    554232317: \"@Azmanrael\",\n",
    "    2164603921: \"@tcmeb\",\n",
    "    252734495: \"@ulusevinc\",\n",
    "    26230808: \"@alymlk\",\n",
    "    951476331413372929: \"@miditak\",\n",
    "    2694287481: \"@TRombudsman\",\n",
    "    804855615185125376: \"@racaronal\",\n",
    "    20957469: \"@hata24tr\",\n",
    "    993493300643549184: \"@ozgur_yilmazs\",\n",
    "    1006173139427086341: \"@Eko20141\",\n",
    "    1006898982121975808: \"@ylsy4\",\n",
    "    1007278964635815936: \"@OsmanogluHande\",\n",
    "    139148275: \"@rosethyler\",\n",
    "    123032207: \"@oguzabel\",\n",
    "    1005131574596206592: \"@ChloeShoun\",\n",
    "    755123745778434052: \"@aysafa2\",\n",
    "    805802477618655233: \"@Sahinde279\",\n",
    "    1004272528485908480: \"@tzslan\",\n",
    "    2797488571: \"@umit_uduru81\",\n",
    "    1003650358399336448: \"@Sherydgn\",\n",
    "    1004016114945454080: \"@ylsy1416\",\n",
    "    100548396: \"@murat_cerit\",\n",
    "    1523815110: \"@ozdogan_ayse\",\n",
    "    1003716166366396416: \"@ibrahim76318357\",\n",
    "    86905010: \"@historian36\",\n",
    "    1004005903216111617: \"@YlsyD\",\n",
    "    1005184823898632192: \"@YlsyMagdur\",\n",
    "    813667892579471360: \"@marslan361\",\n",
    "    895347063298428929: \"@biodegradable\",\n",
    "    1003749486449922048: \"@1416ylsyM\",\n",
    "    859531005010599936: \"@MagdurBursiyer\",\n",
    "    806470658091839488: \"@mebbursiyeri\",\n",
    "    3129651633: \"@gurbuz_ayten\",\n",
    "    1004025265167757314: \"@HakanSandal13\",\n",
    "    170891649: \"@adrianapolisli\",\n",
    "    2509005878: \"@burcinkelez\",\n",
    "    1146032313119236097: \"@MerveKe73927619\",\n",
    "    2262866341: \"@lutfielvan\",\n",
    "    1050449054: \"@AysBenevento\",\n",
    "    986911464: \"@_cevdetyilmaz\",\n",
    "    1487245633: \"@erkanakcay45\",\n",
    "    1003638852471451648: \"@mimesec\",\n",
    "    1587124128: \"@gozturk2013\",\n",
    "    1006992142848446465: \"@ArtukHanefi\",\n",
    "    1283532661: \"@yavuzagiraliog\",\n",
    "   \n",
    "    \n",
    "}\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store user mentions and their counts\n",
    "user_mentions = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        # Filter tweets with specific tweet_client_name values\n",
    "        filtered_df = df[df['tweet_client_name'].isin([\"erased15418350\", \"ylsy ylsy\", \"asd asd afasdf\", \"asd ada sdads\", \"adfa fasd asd\", \"afda sda d\", \"asdasd asd ask asd\"])]\n",
    "\n",
    "        for row in filtered_df['user_mentions']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split user mentions by comma\n",
    "                mentions = row[1:-1].split(',')\n",
    "                mentions = [mention.strip() for mention in mentions if mention.strip() != \"\"]\n",
    "                # Iterate over each user mention\n",
    "                for mention in mentions:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    mention = mention.strip().lower()[1:-1]\n",
    "\n",
    "                    if mention.isdigit():  # Check if the mention is a numeric ID\n",
    "                        mention_id = int(mention)\n",
    "                        if mention_id in id_to_handle:\n",
    "                            mention = id_to_handle[mention_id]\n",
    "                        else:\n",
    "                            mention = mention  # If the mention is not a numeric ID, keep it as it is\n",
    "\n",
    "                    # Increment the count for the user mention in the dictionary\n",
    "                    if mention in user_mentions:\n",
    "                        user_mentions[mention] += 1\n",
    "                    else:\n",
    "                        user_mentions[mention] = 1\n",
    "\n",
    "# Sort the user mentions dictionary by count in descending order and get the top 100\n",
    "top_100_user_mentions = sorted(user_mentions.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "\n",
    "# Extract the user mentions and their counts into separate lists\n",
    "user_mentions_list = [mention[0] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "counts_list = [mention[1] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_mentions_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 100 User Mentions by 7 Suspicious Accounts')\n",
    "plt.tight_layout()\n",
    "\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "# plt.savefig(\"top100userreplies.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the user mentions dictionary by count in descending order and get the top 100\n",
    "top_100_user_mentions = sorted(user_mentions.items(), key=lambda x: x[1], reverse=True)[:50]\n",
    "\n",
    "# Extract the user mentions and their counts into separate lists\n",
    "user_mentions_list = [mention[0] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "counts_list = [mention[1] for mention in top_100_user_mentions][::-1]  # Reverse the list\n",
    "\n",
    "plt.figure(figsize=(15, 20))  # Adjust the figure size as needed for horizontal layout\n",
    "bars = plt.barh(user_mentions_list, counts_list, height=0.7, color='gold')  # Set the bar height and color\n",
    "plt.xscale('log')  # Use logarithmic scale for the x-axis\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('User Mention')\n",
    "plt.title('Top 100 User Mentions by 7 Suspicious Accounts')\n",
    "plt.tight_layout()\n",
    "\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()  # Use get_width() for horizontal bars\n",
    "        plt.text(width, bar.get_y() + bar.get_height() / 2, str(int(width)), ha='right', va='center', color='black', fontsize=13)  # Increase the fontsize to your desired value\n",
    "\n",
    "autolabel(bars)\n",
    "\n",
    "# Save the plot to a file (optional)\n",
    "plt.savefig(\"7accountreplies50.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many tweets are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    total_tweet_count = 0  # Initialize the total count\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            tweet_count = df['tweetid'].nunique()\n",
    "            total_tweet_count += tweet_count  # Accumulate the counts\n",
    "            \n",
    "            print(\"Number of tweets in\", member, \":\", tweet_count)\n",
    "\n",
    "# Print the total number of tweets\n",
    "print(\"Total number of tweets from all CSVs:\", total_tweet_count)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many tweets from 7 apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# List of client names to filter\n",
    "client_names = ['erased15418350', 'ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d', 'asdasd asd ask asd']\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    total_tweet_count = 0  # Initialize the total tweet count\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            filtered_df = df[df['tweet_client_name'].isin(client_names)]\n",
    "            tweet_count = filtered_df['tweetid'].nunique()\n",
    "            total_tweet_count += tweet_count  # Accumulate the counts\n",
    "            \n",
    "            print(\"Number of tweets from specific clients in\", member, \":\", tweet_count)\n",
    "\n",
    "# Print the total number of tweets from specific clients\n",
    "print(\"Total number of tweets from specific clients:\", total_tweet_count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    unique_users = set()  # Initialize a set to store unique userids\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            unique_users.update(df['userid'].unique())  # Update the set with unique userids\n",
    "            \n",
    "    user_count = len(unique_users)  # Count the number of unique userids\n",
    "\n",
    "# Print the total number of unique users\n",
    "print(\"Total number of unique users:\", user_count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total client userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Define the list of desired clients\n",
    "desired_clients = [\"erased15418350\", \"ylsy ylsy\", \"asd asd afasdf\", \"asd ada sdads\", \"adfa fasd asd\", \"afda sda d\", \"asdasd asd ask asd\"]\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    unique_users = set()  # Initialize a set to store unique userids\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            \n",
    "            # Filter the dataframe based on desired clients\n",
    "            filtered_df = df[df['tweet_client_name'].isin(desired_clients)]\n",
    "            \n",
    "            unique_users.update(filtered_df['userid'].unique())  # Update the set with unique userids\n",
    "            \n",
    "    user_count = len(unique_users)  # Count the number of unique userids\n",
    "\n",
    "# Print the total number of unique users\n",
    "print(\"Total number of unique users:\", user_count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# which csv files is this reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    file_names = zObject.namelist()\n",
    "\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith('.csv'):\n",
    "            print(file_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how many users from these 7 apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# List of client names to filter\n",
    "client_names = ['erased15418350', 'ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d', 'asdasd asd ask asd']\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # Store unique userids for each client name\n",
    "    client_userids = {}\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            filtered_df = df[df['tweet_client_name'].isin(client_names)]\n",
    "\n",
    "            # Iterate over each client name\n",
    "            for client_name in client_names:\n",
    "                client_df = filtered_df[filtered_df['tweet_client_name'] == client_name]\n",
    "                unique_userids = client_df['userid'].nunique()\n",
    "                client_userids[client_name] = client_userids.get(client_name, 0) + unique_userids\n",
    "\n",
    "    # Print the number of unique userids for each client name\n",
    "    for client_name, unique_userids in client_userids.items():\n",
    "        print(\"Number of unique userids for\", client_name, \":\", unique_userids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# List of client names to filter\n",
    "client_names = ['erased15418350', 'ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d', 'asdasd asd ask asd']\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # Store unique account creation dates for each client name\n",
    "    client_account_dates = {}\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            filtered_df = df[df['tweet_client_name'].isin(client_names)]\n",
    "\n",
    "            # Iterate over each client name\n",
    "            for client_name in client_names:\n",
    "                client_df = filtered_df[filtered_df['tweet_client_name'] == client_name]\n",
    "                unique_account_dates = client_df['account_creation_date'].nunique()\n",
    "                client_account_dates[client_name] = client_account_dates.get(client_name, 0) + unique_account_dates\n",
    "\n",
    "    # Create a bar graph of unique account creation dates for each client\n",
    "    clients = list(client_account_dates.keys())\n",
    "    counts = list(client_account_dates.values())\n",
    "\n",
    "    plt.bar(clients, counts)\n",
    "    plt.xlabel(\"Client Names\")\n",
    "    plt.ylabel(\"Number of Unique Account Creation Dates\")\n",
    "    plt.title(\"Unique Account Creation Dates for Clients\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# List of client names to filter\n",
    "client_names = ['erased15418350', 'ylsy ylsy', 'asd asd afasdf', 'asd ada sdads', 'adfa fasd asd', 'afda sda d', 'asdasd asd ask asd']\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # Store unique account creation dates for each client name\n",
    "    client_account_dates = {}\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            filtered_df = df[df['tweet_client_name'].isin(client_names)]\n",
    "\n",
    "            # Iterate over each client name\n",
    "            for client_name in client_names:\n",
    "                client_df = filtered_df[filtered_df['tweet_client_name'] == client_name]\n",
    "                unique_account_dates = client_df['account_creation_date'].unique()\n",
    "                client_account_dates[client_name] = unique_account_dates\n",
    "\n",
    "    # Print the account creation dates for each client\n",
    "    for client_name, dates in client_account_dates.items():\n",
    "        print(f\"Client: {client_name}\")\n",
    "        for date in dates:\n",
    "            print(date)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag co-occurrance network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store hashtags and their counts\n",
    "hashtags = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['hashtags']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split hashtags by comma\n",
    "                tags = row[1:-1].split(',')\n",
    "                tags = [t.strip() for t in tags if t.strip() != \"\"]\n",
    "                # Iterate over each hashtag\n",
    "                for tag in tags:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tag = tag.strip().lower()[1:-1]\n",
    "                    # Increment the count for the hashtag in the dictionary\n",
    "                    if tag in hashtags:\n",
    "                        hashtags[tag] += 1\n",
    "                    else:\n",
    "                        hashtags[tag] = 1\n",
    "\n",
    "# Create a co-occurrence matrix\n",
    "co_occurrence_matrix = pd.DataFrame(0, index=hashtags.keys(), columns=hashtags.keys())\n",
    "\n",
    "# Create a zip object again to reset the iterator\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        for row in df['hashtags']:\n",
    "            # Check if the row is not empty\n",
    "            if pd.notnull(row):\n",
    "                # Split hashtags by comma\n",
    "                tags = row[1:-1].split(',')\n",
    "                tags = [t.strip() for t in tags if t.strip() != \"\"]\n",
    "                # Iterate over each pair of hashtags\n",
    "                for i in range(len(tags)):\n",
    "                    for j in range(i + 1, len(tags)):\n",
    "                        tag1 = tags[i].strip().lower()[1:-1]\n",
    "                        tag2 = tags[j].strip().lower()[1:-1]\n",
    "                        # Increment the count in the co-occurrence matrix\n",
    "                        co_occurrence_matrix.loc[tag1, tag2] += 1\n",
    "                        co_occurrence_matrix.loc[tag2, tag1] += 1\n",
    "\n",
    "# Create a graph from the co-occurrence matrix\n",
    "G = nx.from_pandas_adjacency(co_occurrence_matrix)\n",
    "\n",
    "# Set the node sizes based on the hashtag counts\n",
    "node_sizes = [hashtags[tag] for tag in G.nodes()]\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(10, 10))\n",
    "pos = nx.spring_layout(G, k=0.1)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='lightblue', alpha=0.7)\n",
    "nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.3)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "plt.title('Hashtag Co-occurrence Network')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a defaultdict to store hashtags and their counts\n",
    "hashtags = defaultdict(int)\n",
    "G = nx.Graph()\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for fpath in tqdm([fpath for fpath in zObject.namelist() if fpath.endswith(\".csv\")]):\n",
    "        df = pd.read_csv(zObject.open(fpath))\n",
    "        # Split hashtags by comma and remove empty strings\n",
    "        df = df[df['hashtags'].notna()]\n",
    "        tags = df['hashtags'].tolist()\n",
    "        \n",
    "        tags = [tag_list[1:-1].split(\",\") for tag_list in tags]\n",
    "        cleaned_tags = []\n",
    "        for tag_list in tags:\n",
    "            new_tag_list = []\n",
    "            for t in tag_list:\n",
    "                if t.strip() != \"\":\n",
    "                    t = re.sub(\"'\",\"\",t)\n",
    "                    new_tag_list.append(t.lower().strip())\n",
    "            if len(new_tag_list) > 0:\n",
    "                cleaned_tags.append(new_tag_list)\n",
    "        \n",
    "                \n",
    "        for tags in cleaned_tags:\n",
    "            len_tags = len(tags)\n",
    "            if len_tags > 1:\n",
    "                for i in range(len_tags):\n",
    "                    for j in range(i+1,len_tags):\n",
    "                        if G.has_edge(tags[i], tags[j]):\n",
    "                            G.edges[tags[i], tags[j]][\"weight\"] += 1\n",
    "                        else:\n",
    "                            G.add_edge(tags[i], tags[j], weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G,\"fullhashtag.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0\n",
    "for e in G.edges:\n",
    "    print(e, G.get_edge_data(e[0],e[1]))\n",
    "    counter += 1\n",
    "    if counter > 100:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gexf(\"/cta/users/uduygu/project1/full_net.gexf\")\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the network\n",
    "threshold = 25\n",
    "NEW_G = nx.Graph()\n",
    "for edge in list(G.edges()).copy():\n",
    "    weight = G.get_edge_data(edge[0],edge[1])[\"weight\"]\n",
    "    if weight >= threshold:\n",
    "        NEW_G.add_edge(edge[0],edge[1],weight=weight)\n",
    "print(NEW_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(NEW_G,\"25filteredhashtag.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mention test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty dictionary to store tweet texts and their counts\n",
    "tweet_texts = {}\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"userid\" equal to \"1628824092\"\n",
    "            filtered_df = df[df['user_mentions'].str.contains('1847174592|1482806160| 3555190636|466757008|442252059|1132163245| 4409222427|876745005561466880|3291835017')]\n",
    "\n",
    "\n",
    "            for row in filtered_df['tweet_text']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(row):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    tweet_text = row.strip()\n",
    "                    print(tweet_text) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how many users have mentioned the ataturk nodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty set to store unique user IDs\n",
    "user_ids = set()\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"userid\" equal to \"1628824092\"\n",
    "            filtered_df = df[df['user_mentions'].str.contains('1847174592|1482806160|3555190636|466757008|442252059|1132163245|4409222427|876745005561466880|329183501|1631039467')]\n",
    "\n",
    "            for user_id in filtered_df['userid']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(user_id):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    user_id = user_id.strip()\n",
    "                    user_ids.add(user_id)\n",
    "\n",
    "# Display the unique user IDs\n",
    "for user_id in user_ids:\n",
    "    print(user_id)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many retweets in th dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create variables to store the counts\n",
    "false_count = 0\n",
    "true_count = 0\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Count the occurrences of 'FALSE' and 'TRUE' in the \"is_retweet\" column\n",
    "            false_count += (df['is_retweet'] == 'FALSE').sum()\n",
    "            true_count += (df['is_retweet'] == 'TRUE').sum()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Total count of 'False':\", false_count)\n",
    "print(\"Total count of 'True':\", true_count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# userid dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    unique_users = {}  # Initialize a dictionary to store unique userids\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            unique_user_list = df['userid'].unique()\n",
    "            for user in unique_user_list:\n",
    "                unique_users[user] = True  # Store unique userids as keys in the dictionary\n",
    "            \n",
    "    user_count = len(unique_users)  # Count the number of unique userids\n",
    "\n",
    "# Print the total number of unique users\n",
    "print(\"Total number of unique users:\", user_count)\n",
    "\n",
    "# Print the dictionary of unique userids\n",
    "print(\"Unique userids:\", unique_users.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    mentioned_users = {}  # Initialize a dictionary to store mentioned users\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            \n",
    "            # Filter out rows with non-null 'user_mentions'\n",
    "            df = df[df['user_mentions'].notna()]\n",
    "            \n",
    "            mentions_list = df['user_mentions'].tolist()\n",
    "            mentions_list = [mention_list[1:-1].split(\",\") for mention_list in mentions_list]\n",
    "            \n",
    "            cleaned_mentions = []\n",
    "            for mention_list in mentions_list:\n",
    "                new_mention_list = []\n",
    "                for t in mention_list:\n",
    "                    if t.strip() != \"\":\n",
    "                        t = re.sub(\"'\", \"\", t)\n",
    "                        new_mention_list.append(t.lower().strip())\n",
    "                if len(new_mention_list) > 0:\n",
    "                    cleaned_mentions.append(new_mention_list)\n",
    "            \n",
    "            for mention_list in cleaned_mentions:\n",
    "                for mention in mention_list:\n",
    "                    if mention not in mentioned_users:\n",
    "                        mentioned_users[mention] = True  # Store mentioned users as keys in the dictionary\n",
    "\n",
    "# Print the total number of mentioned users\n",
    "user_count = len(mentioned_users)\n",
    "print(\"Total number of mentioned users:\", user_count)\n",
    "\n",
    "# Print the list of mentioned users\n",
    "print(\"Mentioned users:\")\n",
    "for user in mentioned_users.keys():\n",
    "    print(user)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    mentioned_users = set()  # Initialize a set to store unique mentioned users\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            \n",
    "            # Filter out rows with non-null 'user_mentions'\n",
    "            df = df[df['user_mentions'].notna()]\n",
    "            \n",
    "            mentions_list = df['user_mentions'].tolist()\n",
    "            mentions_list = [mention_list[1:-1].split(\",\") for mention_list in mentions_list]\n",
    "            \n",
    "            for mention_list in mentions_list:\n",
    "                for mention in mention_list:\n",
    "                    mention = mention.strip()\n",
    "                    if mention:\n",
    "                        mentioned_users.add(mention.lower())  # Add mentioned users to the set\n",
    "\n",
    "# Print the total number of mentioned users\n",
    "user_count = len(mentioned_users)\n",
    "print(\"Total number of mentioned users:\", user_count)\n",
    "\n",
    "# Print the unique mentioned users\n",
    "print(\"Unique mentioned users:\")\n",
    "for user in mentioned_users:\n",
    "    print(user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sum = len(mentioned_users)\n",
    "\n",
    "# Print the sum of unique users\n",
    "print(\"Sum of unique users:\", user_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mentioned users:\")\n",
    "for user in mentioned_users.keys():\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    unique_users = set()  # Initialize a set to store unique userids\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            unique_users.update(df['userid'].unique())  # Add unique userids to the set\n",
    "            \n",
    "    user_count = len(unique_users)  # Count the number of unique userids\n",
    "\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            \n",
    "            # Filter out rows with non-null 'user_mentions'\n",
    "            df = df.dropna(subset=['user_mentions'])\n",
    "            \n",
    "            mentions_list = df['user_mentions'].tolist()\n",
    "            mentions_list = [mention_list[1:-1].split(\",\") for mention_list in mentions_list]\n",
    "            \n",
    "            cleaned_mentions = []\n",
    "            for mention_list in mentions_list:\n",
    "                new_mention_list = []\n",
    "                for t in mention_list:\n",
    "                    if t.strip() != \"\":\n",
    "                        t = re.sub(\"'\", \"\", t)\n",
    "                        new_mention_list.append(t.lower().strip())\n",
    "                if len(new_mention_list) > 0:\n",
    "                    cleaned_mentions.append(new_mention_list)\n",
    "            \n",
    "            for mention_list in cleaned_mentions:\n",
    "                mentioned_users.update(mention_list)  # Add mentioned users to the set\n",
    "\n",
    "# Count the number of matches and non-matches\n",
    "match_count = len(unique_users.intersection(mentioned_users))\n",
    "no_match_count = len(unique_users.difference(mentioned_users))\n",
    "\n",
    "print(\"Yes count:\", match_count)\n",
    "print(\"No count:\", no_match_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Initialize sets to store unique userids and mentioned users\n",
    "unique_users = set()\n",
    "mentioned_users = set()\n",
    "\n",
    "# Extract unique userids and mentioned users from the zip file\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            \n",
    "            # Extract unique userids\n",
    "            unique_users.update(df['userid'].unique())\n",
    "            \n",
    "            # Extract mentioned users\n",
    "            df = df.dropna(subset=['user_mentions'])\n",
    "            mentions_list = df['user_mentions'].tolist()\n",
    "            \n",
    "            for mention_list in mentions_list:\n",
    "                mention_list = mention_list[1:-1].split(\",\")\n",
    "                cleaned_mentions = [re.sub(\"'\", \"\", t.lower().strip()) for t in mention_list if t.strip() != \"\"]\n",
    "                if len(cleaned_mentions) > 0:\n",
    "                    mentioned_users.update(cleaned_mentions)\n",
    "\n",
    "# Count the number of matches and non-matches\n",
    "match_count = len(unique_users.intersection(mentioned_users))\n",
    "no_match_count = len(unique_users - mentioned_users)\n",
    "\n",
    "print(\"Yes count:\", match_count)\n",
    "print(\"No count:\", no_match_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the mentioned users are:\")\n",
    "mentioned_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the unique uesrs are:\")\n",
    "unique_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_intersect = unique_users.intersection(mentioned_users)\n",
    "#no_match_count = len(unique_users - mentioned_users)\n",
    "print(my_intersect)\n",
    "print(\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_match = unique_users - mentioned_users\n",
    "print(no_match)\n",
    "print(\"something\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    unique_users = set()  # Initialize a set to store unique userids\n",
    "    replied_users = set()  # Initialize a set to store replied userids\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            unique_users.update(df['userid'].unique())  # Add unique userids to the set\n",
    "            \n",
    "            # Filter out rows with non-null 'in_reply_to_userid'\n",
    "            df = df.dropna(subset=['in_reply_to_userid'])\n",
    "            \n",
    "            replies_list = df['in_reply_to_userid'].tolist()\n",
    "            \n",
    "            for reply_list in replies_list:\n",
    "                replied_users.update([reply_list])  # Add replied users to the set\n",
    "\n",
    "# Count the number of matches and non-matches\n",
    "match_count = len(unique_users.intersection(replied_users))\n",
    "no_match_count = len(unique_users.difference(replied_users))\n",
    "\n",
    "print(\"Yes count:\", match_count)\n",
    "print(\"No count:\", no_match_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    unique_replies = {}  # Initialize a dictionary to store unique userids\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            unique_reply_list = df['in_reply_to_userid'].unique()\n",
    "            for reply in unique_reply_list:\n",
    "                unique_replies[reply] = True  # Store unique userids as keys in the dictionary\n",
    "            \n",
    "    reply_count = len(unique_replies)  # Count the number of unique userids\n",
    "\n",
    "# Print the total number of unique users\n",
    "print(\"Total number of unique users:\", reply_count)\n",
    "\n",
    "# Print the dictionary of unique userids\n",
    "print(\"Unique userids:\", list(unique_replies.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    unique_users = set()  # Initialize a set to store unique userids\n",
    "    replied_users = set()  # Initialize a set to store replied userids\n",
    "\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            unique_users.update(df['userid'].unique())  # Add unique userids to the set\n",
    "\n",
    "            # Filter out rows with non-null 'in_reply_to_userid'\n",
    "            df = df.dropna(subset=['in_reply_to_userid'])\n",
    "\n",
    "            # Get the pairs of userid and reply\n",
    "            pairs = df[['userid', 'in_reply_to_userid']].values.tolist()\n",
    "\n",
    "            # Print the matching pairs\n",
    "            for pair in pairs:\n",
    "                if pair[0] == pair[1]:\n",
    "                    print(pair[0], pair[1])\n",
    "\n",
    "                replied_users.update([pair[1]])  # Add replied users to the set\n",
    "\n",
    "# Count the number of matches and non-matches\n",
    "match_count = len(unique_users.intersection(replied_users))\n",
    "no_match_count = len(unique_users.difference(replied_users))\n",
    "\n",
    "print(\"Yes count:\", match_count)\n",
    "print(\"No count:\", no_match_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Handles Alive??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "import tweepy\n",
    "import csv\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Initialize sets to store mentioned users\n",
    "mentioned_users = set()\n",
    "\n",
    "# Extract mentioned users from the zip file\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            \n",
    "            # Extract mentioned users\n",
    "            df = df.dropna(subset=['user_mentions'])\n",
    "            mentions_list = df['user_mentions'].tolist()\n",
    "            \n",
    "            for mention_list in mentions_list:\n",
    "                mention_list = mention_list[1:-1].split(\",\")\n",
    "                cleaned_mentions = [re.sub(\"'\", \"\", t.lower().strip()) for t in mention_list if t.strip() != \"\"]\n",
    "                if len(cleaned_mentions) > 0:\n",
    "                    mentioned_users.update(cleaned_mentions)\n",
    "\n",
    "# Twitter API credentials\n",
    "consumer_key = 'RaQOhZQ27heCqyfnehZ7TQBT6'\n",
    "consumer_secret = 'YjGdKDL0JTk2zdDkQunrBM2C8rJnWI81o3Y7Dqx5sz7cTwWAOS'\n",
    "access_token = '1165915696745914368-nZ2rvPdxY6QAUAN902fE8aVsQmMJRv'\n",
    "access_token_secret = 'w5r2ahIR6EI06WCZCOHz1zLXkuiE82ZcdS6ZMaoLzPsvQ'\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Set a new list object\n",
    "myHandles = []\n",
    "errors = 0\n",
    "\n",
    "# Define the cleaned_mentions list here\n",
    "cleaned_mentions = list(mentioned_users)\n",
    "\n",
    "# Loop through the list of cleaned_mentions\n",
    "for mention in cleaned_mentions:\n",
    "    try:\n",
    "        user = api.get_user(screen_name=mention)\n",
    "        handle = user.screen_name\n",
    "        myHandles.append(handle)\n",
    "    except AttributeError:\n",
    "        print(f\"Error retrieving handle for mention '{mention}': {str(e)}\")\n",
    "        errors += 1\n",
    "\n",
    "# Print the lists\n",
    "print('Mentions:', cleaned_mentions)\n",
    "print('Twitter Handles:', myHandles)\n",
    "\n",
    "# Set a filename based on the current time\n",
    "csvfilename = \"csvoutput-\" + time.strftime(\"%Y%m%d%-H%M%S\") + \".csv\"\n",
    "print('We also outputted a CSV-file named ' + csvfilename + ' to your file parent directory')\n",
    "\n",
    "with open(csvfilename, 'w') as myfile:\n",
    "    wr = csv.writer(myfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    wr.writerow(['mention', 'twitter-handle'])\n",
    "    j = 0\n",
    "\n",
    "    for mention in cleaned_mentions:\n",
    "        writeline = cleaned_mentions[j], myHandles[j]\n",
    "        wr.writerow(writeline)\n",
    "        j = j + 1\n",
    "\n",
    "# Print counts\n",
    "total_handles = len(myHandles)\n",
    "print(\"Total Handles:\", total_handles)\n",
    "print(\"Total Errors:\", errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    tweet_counts = {}  # Dictionary to store tweet counts per CSV\n",
    "    \n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "            tweet_count = df['tweetid'].nunique()\n",
    "            tweet_counts[member] = tweet_count\n",
    "            \n",
    "            print(\"Number of tweets in\", member, \":\", tweet_count)\n",
    "\n",
    "# Plot the graph\n",
    "plt.bar(tweet_counts.keys(), tweet_counts.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('CSV File')\n",
    "plt.ylabel('Tweet Count')\n",
    "plt.title('Tweet Count per CSV File')\n",
    "plt.show()\n",
    "\n",
    "# Print the total number of tweets\n",
    "total_tweet_count = sum(tweet_counts.values())\n",
    "print(\"Total number of tweets from all CSVs:\", total_tweet_count)\n",
    "\n",
    "#plt.savefig(\"top100usermentions.pdf\", bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    2009: 153,\n",
    "    2019: 10218345,\n",
    "    2017: 6537971,\n",
    "    2020: 859516,\n",
    "    2015: 2821965,\n",
    "    2014: 2661507,\n",
    "    2010: 2172,\n",
    "    2016: 4743750,\n",
    "    2011: 35100,\n",
    "    2013: 793777,\n",
    "    2018: 8023579,\n",
    "    2012: 250689\n",
    "}\n",
    "\n",
    "# Sort the data by year\n",
    "sorted_data = sorted(data.items())\n",
    "\n",
    "# Extract the years and tweet counts as separate lists\n",
    "years, tweet_counts = zip(*sorted_data)\n",
    "\n",
    "# Create the line plot with a logarithmic scale for the y-axis\n",
    "plt.plot(years, tweet_counts, marker='o')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Tweets (log scale)')\n",
    "plt.title('Number of Tweets Posted Each Year')\n",
    "\n",
    "# Set the y-axis scale to logarithmic\n",
    "plt.yscale('log')\n",
    "\n",
    "# Display the line graph\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    2009: 153,\n",
    "    2019: 10218345,\n",
    "    2017: 6537971,\n",
    "    2020: 859516,\n",
    "    2015: 2821965,\n",
    "    2014: 2661507,\n",
    "    2010: 2172,\n",
    "    2016: 4743750,\n",
    "    2011: 35100,\n",
    "    2013: 793777,\n",
    "    2018: 8023579,\n",
    "    2012: 250689\n",
    "}\n",
    "\n",
    "# Sort the data by year\n",
    "sorted_data = sorted(data.items())\n",
    "\n",
    "# Extract the years and tweet counts as separate lists\n",
    "years, tweet_counts = zip(*sorted_data)\n",
    "\n",
    "# Create the line plot with a logarithmic scale for the y-axis\n",
    "plt.plot(years, tweet_counts, marker='o', color='blue', linestyle='-', linewidth=2)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Tweets (log scale)')\n",
    "plt.title('Number of Tweets Posted Each Year')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Set the x-axis ticks and labels with rotation\n",
    "plt.xticks(years, rotation=45)\n",
    "\n",
    "\n",
    "# Increase the figure size for better readability\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Save the graph to a file (e.g., PNG format)\n",
    "plt.savefig('tweet_counts.pdf')\n",
    "\n",
    "# Display the line graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    2009: 153,\n",
    "    2019: 10218345,\n",
    "    2017: 6537971,\n",
    "    2020: 859516,\n",
    "    2015: 2821965,\n",
    "    2014: 2661507,\n",
    "    2010: 2172,\n",
    "    2016: 4743750,\n",
    "    2011: 35100,\n",
    "    2013: 793777,\n",
    "    2018: 8023579,\n",
    "    2012: 250689\n",
    "}\n",
    "\n",
    "# Sort the data by year\n",
    "sorted_data = sorted(data.items())\n",
    "\n",
    "# Extract the years and tweet counts as separate lists\n",
    "years, tweet_counts = zip(*sorted_data)\n",
    "\n",
    "# Increase the figure size for better readability\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Create the line plot with a logarithmic scale for the y-axis\n",
    "plt.plot(years, tweet_counts, marker='o', color='blue', linestyle='-', linewidth=2)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Tweets (log scale)')\n",
    "plt.title('Number of Tweets Posted Each Year')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Set the x-axis ticks and labels with rotation\n",
    "plt.xticks(years, rotation=45)\n",
    "\n",
    "# Save the graph to a file (e.g., PDF format)\n",
    "plt.savefig('tweet_counts.pdf')\n",
    "\n",
    "# Display the line graph\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    2009: 153,\n",
    "    2019: 10218345,\n",
    "    2017: 6537971,\n",
    "    2020: 859516,\n",
    "    2015: 2821965,\n",
    "    2014: 2661507,\n",
    "    2010: 2172,\n",
    "    2016: 4743750,\n",
    "    2011: 35100,\n",
    "    2013: 793777,\n",
    "    2018: 8023579,\n",
    "    2012: 250689\n",
    "}\n",
    "\n",
    "# Sort the data by year\n",
    "sorted_data = sorted(data.items())\n",
    "\n",
    "# Extract the years and tweet counts as separate lists\n",
    "years, tweet_counts = zip(*sorted_data)\n",
    "\n",
    "# Increase the figure size for better readability\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Create the line plot with a logarithmic scale for the y-axis\n",
    "plt.plot(years, tweet_counts, marker='o', color='blue', linestyle='-', linewidth=2)\n",
    "\n",
    "# Add the counts on top of the dots\n",
    "for i, count in enumerate(tweet_counts):\n",
    "    plt.text(years[i], count, str(count), ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Tweets (log scale)')\n",
    "plt.title('Number of Tweets Posted Each Year')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Set the x-axis ticks and labels with rotation\n",
    "plt.xticks(years, rotation=45)\n",
    "\n",
    "# Save the graph to a file (e.g., PDF format)\n",
    "plt.savefig('tweet_counts.pdf')\n",
    "\n",
    "# Display the line graph\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from top 10 atatrk nodes how many of them mentioned by unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty set to store unique user IDs\n",
    "user_ids = set()\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            # Filter rows with \"userid\" equal to \"1628824092\"\n",
    "            filtered_df = df[df['user_mentions'].str.contains('1847174592|1482806160|3555190636|466757008|442252059|1132163245|4409222427|876745005561466880|329183501|1631039467')]\n",
    "\n",
    "            for user_id in filtered_df['userid']:\n",
    "                # Check if the row is not empty\n",
    "                if pd.notnull(user_id):\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    user_id = user_id.strip()\n",
    "                    user_ids.add(user_id)\n",
    "\n",
    "# Display the unique user IDs\n",
    "for user_id in user_ids:\n",
    "    print(user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create an empty set to store unique user IDs\n",
    "user_ids = set()\n",
    "\n",
    "# Define the list of user mentions\n",
    "user_mentions = ['1847174592', '1482806160', '3555190636', '466757008', '442252059',\n",
    "                    '1132163245', '4409222427', '876745005561466880', '329183501', '1631039467']\n",
    "# Find combinations of three user mentions\n",
    "combinations = list(itertools.combinations(user_mentions, 3))\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in tqdm(zObject.namelist(), total=18):\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "            for combo in combinations:\n",
    "                # Filter rows with the combination of user mentions\n",
    "                filtered_df = df[df['user_mentions'].str.contains('|'.join(combo))]\n",
    "                for user_id in filtered_df['userid']:\n",
    "                    # Remove leading and trailing whitespaces\n",
    "                    user_id = user_id.strip()\n",
    "                    user_ids.add(user_id)\n",
    "\n",
    "user_ids = list(user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in user_ids[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/XXX\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    dfs = []  # List to store DataFrames\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            # read data in chunks of size 100000\n",
    "            chunks = pd.read_csv(zObject.open(member), chunksize=100000)\n",
    "            for chunk in chunks:\n",
    "                dfs.append(chunk)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "all_tweets = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Create a new DataFrame that groups by 'userid' and counts 'tweetid'\n",
    "tweets_per_user = all_tweets.groupby('userid')['tweetid'].count().reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "tweets_per_user.columns = ['userid', 'tweet_count']\n",
    "\n",
    "# Now we can plot this as a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(tweets_per_user['tweet_count'], bins=50, log=True, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Tweets Per User')\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.ylabel('Number of Users (Log Scale)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Correct the path to the zip file\n",
    "path1 = \"/c\"\n",
    "\n",
    "# Create a zip object\n",
    "with zipfile.ZipFile(path1, 'r') as zObject:\n",
    "    dfs = []  # List to store DataFrames\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            # read data in chunks of size 100000\n",
    "            chunks = pd.read_csv(zObject.open(member), chunksize=100000)\n",
    "            for chunk in chunks:\n",
    "                dfs.append(chunk)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "all_tweets = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Create a new DataFrame that groups by 'userid' and counts 'tweetid'\n",
    "tweets_per_user = all_tweets.groupby('userid')['tweetid'].count().reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "tweets_per_user.columns = ['userid', 'tweet_count']\n",
    "\n",
    "# Now we can plot this as a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use numpy's arange() function to create bins\n",
    "bins = np.arange(1, tweets_per_user['tweet_count'].max() + 1)\n",
    "\n",
    "plt.hist(tweets_per_user['tweet_count'], bins=bins, log=True, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Tweets Per User')\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.ylabel('Number of Users (Log Scale)')\n",
    "plt.xticks(bins)  # Set x-axis ticks to match bins\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy's arange() function to create bins of width 10\n",
    "bins = np.arange(1, tweets_per_user['tweet_count'].max() + 1, 10)\n",
    "\n",
    "\n",
    "plt.hist(tweets_per_user['tweet_count'], bins=bins, log=True, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Tweets Per User')\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.ylabel('Number of Users (Log Scale)')\n",
    "plt.xticks(bins)  # Set x-axis ticks to match bins\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy's logspace() function to create logarithmically spaced bins\n",
    "bins = np.logspace(0, np.log10(tweets_per_user['tweet_count'].max()), num=50)\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "plt.hist(tweets_per_user['tweet_count'], bins=bins, log=True, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Tweets Per User')\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.ylabel('Number of Users (Log Scale)')\n",
    "plt.xticks(bins)  # Set x-axis ticks to match bins\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a cumulative distribution\n",
    "plt.hist(tweets_per_user['tweet_count'], bins=50, log=True, color='skyblue', edgecolor='black', cumulative=True)\n",
    "plt.title('Cumulative Distribution of Tweets Per User')\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.ylabel('Cumulative Proportion of Users (Log Scale)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
