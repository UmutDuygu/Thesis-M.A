{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n",
      "/tmp/ipykernel_356506/335624985.py:6: DtypeWarning: Columns (15,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(zObject.open(member))\n"
     ]
    }
   ],
   "source": [
    "df = \"/ctc/DATASTORE/TwitterReleases/InformationOperations/202006/hashed_2020_05_turkey_052020_turkey_052020_tweets_csv_hashed.zip\"\n",
    "with zipfile.ZipFile(df, 'r') as zObject:\n",
    "    # List the contents of the zip file\n",
    "    for member in zObject.namelist():\n",
    "        if member.endswith(\".csv\"):\n",
    "            df = pd.read_csv(zObject.open(member))\n",
    "\n",
    "\n",
    "df = df[df['user_mentions'].notna()]  # Filter out rows with NaN values in 'user_mentions' column\n",
    "mentions = df['user_mentions'].tolist()  # Convert 'user_mentions' column to a list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_mentions = []\n",
    "for mention_list in mentions:\n",
    "    mention_list = re.sub(r\"[^\\w\\s,]\", \"\", mention_list)  # Remove non-alphanumeric characters except commas\n",
    "    mention_list = mention_list.split(\",\")  # Split the string by commas\n",
    "    mention_list = [mention.strip().lower() for mention in mention_list if mention.strip() != \"\"]  # Clean and filter mentions\n",
    "    cleaned_mentions.append(mention_list)\n",
    "\n",
    "df['cleaned_user_mentions'] = cleaned_mentions  # Create a new column with cleaned mentions\n",
    "filtered_df = df[df['tweet_text'].str.contains(\"erdogan|akp\", case=False) & df['cleaned_user_mentions'].apply(lambda x: bool(set(x) & set([\"1847174592\",\"1482806160\",\"3555190636\",\"466757008\",\"442252059\",\"1132163245\",\"4409222427\",\"876745005561466880\",\"3291835017\",\"1631039467\"])))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>user_profile_url</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>cleaned_user_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweetid, userid, user_display_name, user_screen_name, user_reported_location, user_profile_description, user_profile_url, follower_count, following_count, account_creation_date, account_language, tweet_language, tweet_text, tweet_time, tweet_client_name, in_reply_to_userid, in_reply_to_tweetid, quoted_tweet_tweetid, is_retweet, retweet_userid, retweet_tweetid, latitude, longitude, quote_count, reply_count, like_count, retweet_count, hashtags, urls, user_mentions, cleaned_user_mentions]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "#!pip3 install zemberek-python\n",
    "\n",
    "\n",
    "from zemberek import (\n",
    "    TurkishSpellChecker,\n",
    "    TurkishSentenceNormalizer,\n",
    "    TurkishSentenceExtractor,\n",
    "    TurkishMorphology,\n",
    "    TurkishTokenizer\n",
    ")\n",
    "\n",
    "zemberek_tokenizer = TurkishTokenizer.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "\n",
    "def text_preprocess(text):\n",
    "    allowed_types = ['WordWithSymbol', 'Word', 'Punctuation', 'Number', 'UnknownWord']\n",
    "    translator = str.maketrans(string.punctuation.replace('.','').replace('@',''), ' '*len(string.punctuation.replace('.','').replace('@','')))\n",
    "    \n",
    "#    text = deEmojify(text)\n",
    "    text = \" \".join([token.content for token in zemberek_tokenizer.tokenize(text) if token.type_.name in allowed_types])\n",
    "    text = text.translate(translator)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = [word for word in text.split()]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_356506/706462811.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['processed_text'] = df.tweet_text.apply(lambda x: text_preprocess(x))\n"
     ]
    }
   ],
   "source": [
    "filtered_df['processed_text'] = df.tweet_text.apply(lambda x: text_preprocess(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              bu benim hayat felsefem\n",
       "1    Günaydın hayırlı günler Dünyadaki en guzel duy...\n",
       "2                                                     \n",
       "3    Oh be . 5 sorudan 3 ünü çözdüm . Eğer hepsi do...\n",
       "4    Tek istedigim birlikte yüzlerce fotografimiz o...\n",
       "5    Eygi bugün ne yazmış Modern Türkiye Batarmış A...\n",
       "6    Aşk celladindan ne çikar madem ki yar vardır ....\n",
       "7    CeHaPe ile hizmet farkımız Onlar kafa çekerek ...\n",
       "8    O sadece KÜRTÇE albüm çıkartıcam dedi ve şeref...\n",
       "9        yarın sınavım var ve ben çalışmak istemiyorum\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.processed_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cta/users/uduygu/project1/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install transformers\n",
    "#!pip3 install torch\n",
    "#!pip3 install torch torchvision\n",
    "#!pip3 install xformers\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer,pipeline, AutoModelForSequenceClassification \n",
    "\n",
    "\n",
    "model_2 = AutoModelForSequenceClassification.from_pretrained(\"kuzgunlar/electra-turkish-sentiment-analysis\")\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"kuzgunlar/electra-turkish-sentiment-analysis\")\n",
    "\n",
    "sa_2 = pipeline(\"sentiment-analysis\", tokenizer=tokenizer_2, model=model_2)\n",
    "\n",
    "\n",
    "def sentiment_analyzer(text):\n",
    "    result = sa_2(text)\n",
    "    \n",
    "    if result[0]['score'] <= 0.7:\n",
    "        sentiment = 0\n",
    "    \n",
    "    else:\n",
    "        if result[0]['label'] == 'Positive':\n",
    "            sentiment = 1\n",
    "\n",
    "        else:\n",
    "            sentiment = -1\n",
    "            \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_label(text):\n",
    "    score = sa_2(text)\n",
    "    label = score[0]['label']\n",
    "    return label\n",
    "\n",
    "def sentiment_score(text):\n",
    "    score = sa_2(text)\n",
    "    score = score[0]['score'] \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_356506/2369780362.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['sentiment_label'] = filtered_df.processed_text.apply(lambda x: sentiment_label(x))\n",
      "/tmp/ipykernel_356506/2369780362.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['sentiment_score'] = filtered_df.processed_text.apply(lambda x: sentiment_score(x))\n"
     ]
    }
   ],
   "source": [
    "#specific charchter tweets\n",
    "#filtered_df['processed_text'] = filtered_df.tweet_text.apply(lambda x: text_preprocess(x))\n",
    "\n",
    "filtered_df['sentiment_label'] = filtered_df.processed_text.apply(lambda x: sentiment_label(x))\n",
    "filtered_df['sentiment_score'] = filtered_df.processed_text.apply(lambda x: sentiment_score(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_label\n",
       "Positive    144362\n",
       "Negative    106327\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['sentiment_label'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment for top 10 atatürk including nodes from mentions network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91872140057238"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['sentiment_score'].mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
